{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3TTppBdUSal",
        "outputId": "dfbd1d95-13b5-427c-b6ae-f5c5884a8745"
      },
      "id": "S3TTppBdUSal",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:47.060557Z",
          "start_time": "2025-07-12T13:58:39.865457Z"
        },
        "id": "672e53594437abc"
      },
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "from setuptools.sandbox import save_argv\n",
        "\n",
        "from tool import preprocess\n",
        "from tool import customdataset"
      ],
      "id": "672e53594437abc",
      "outputs": [],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "id": "b828e981",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.021886Z",
          "start_time": "2025-07-12T13:58:47.066569Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b828e981",
        "outputId": "79071b98-c3ca-4174-994c-3648d18511d3"
      },
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from networkx.readwrite.json_graph import adjacency\n",
        "!pip install faiss-cpu\n",
        "import faiss\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "id": "e99a31348e0a553",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.234186Z",
          "start_time": "2025-07-12T13:58:50.180933Z"
        },
        "id": "e99a31348e0a553"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "outputs": [],
      "execution_count": 39
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.267980Z",
          "start_time": "2025-07-12T13:58:50.261090Z"
        },
        "id": "b20989f1541fb122"
      },
      "cell_type": "code",
      "source": [
        "path = 'MicroLens-50k_pairs.csv'\n",
        "user = 'user'\n",
        "item = 'item'\n",
        "user_id = 'user_id'\n",
        "item_id = 'item_id'\n",
        "timestamp = 'timestamp'\n",
        "save_dir = './embeddings'\n",
        "top_k = 10\n",
        "num_workers = 10\n",
        "k_neg = 10\n",
        "# path = pd.read_csv('MicroLens-50k_pairs.csv')"
      ],
      "id": "b20989f1541fb122",
      "outputs": [],
      "execution_count": 40
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.578506Z",
          "start_time": "2025-07-12T13:58:50.287146Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de02a54222d2235",
        "outputId": "774c6cab-f337-415c-d1a4-11f5d75f8fa3"
      },
      "cell_type": "code",
      "source": [
        "dataset_pd,num_users,num_items = preprocess.openAndSort(path,user_id=user,item_id=item,timestamp='timestamp')"
      ],
      "id": "de02a54222d2235",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset base informationÔºö\n",
            "- number of usersÔºö50000\n",
            "- number of itemsÔºö19220\n",
            "- number of rowsÔºö359708\n"
          ]
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "id": "8b8ae0c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.601335Z",
          "start_time": "2025-07-12T13:58:50.596244Z"
        },
        "id": "8b8ae0c7"
      },
      "source": [
        "# # order by user,timestamp\n",
        "# filtered_df = dataset_pd.sort_values(by=[\"user\", \"timestamp\"])\n"
      ],
      "outputs": [],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "id": "2d2d4de256fd88a5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.630564Z",
          "start_time": "2025-07-12T13:58:50.625626Z"
        },
        "id": "2d2d4de256fd88a5"
      },
      "source": [
        "# def split(df, user_id, item_id, timestamp):\n",
        "#\n",
        "#     # Ëé∑ÂèñÊØè‰∏™Áî®Êà∑ÁöÑÊúÄÂêé‰∏ÄÊù°ËÆ∞ÂΩï‰Ωú‰∏∫ test\n",
        "#     test_df = df.groupby(user_id).tail(1)\n",
        "#     train_df = df.drop(index=test_df.index)\n",
        "#\n",
        "#     # ËøáÊª§ test ‰∏≠ÈÇ£‰∫õ user/item ‰∏çÂú® train ‰∏≠ÁöÑ\n",
        "#     train_users = set(train_df[user_id])\n",
        "#     train_items = set(train_df[item_id])\n",
        "#\n",
        "#     # Á°Æ‰øùÊµãËØïÈõÜ‰∏≠Âá∫Áé∞ÁöÑÁî®Êà∑/Áâ©ÂìÅÈÉΩÂú®ËÆ≠ÁªÉÈõÜ‰∏≠Âá∫Áé∞ËøáÔºåÈÅøÂÖçÊüê‰∏™Áâ©ÂìÅ‰ªÖÂá∫Áé∞Âú®ÊµãËØïÈõÜ‰∏≠ÔºåÊ≤°ÊúâÂú®ËÆ≠ÁªÉÈõÜ‰∏≠ÂæóÂà∞ËøáËÆ≠ÁªÉ\n",
        "#     test_df = test_df[\n",
        "#         test_df[user_id].isin(train_users) &\n",
        "#         test_df[item_id].isin(train_items)\n",
        "#     ]\n",
        "#     # .reset_indexÈáçÁΩÆ df ÁöÑÁ¥¢ÂºïÔºå‰ΩøÂæó‰∏çËøûÁª≠ÁöÑÁ¥¢ÂºïÈáçÊñ∞ÊéíÂàóÊï¥ÈΩêÔºådrop=TrueË°®ÊòéÊóßÁöÑÁ¥¢Âºï‰∏çÂÜç‰øùÁïô\n",
        "#     return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
      ],
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "id": "3db1146761e45165",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:50.861004Z",
          "start_time": "2025-07-12T13:58:50.639579Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3db1146761e45165",
        "outputId": "c9fedd02-b326-4943-d0bf-562bc7d01546"
      },
      "source": [
        "\n",
        "train_df, test_df = preprocess.split(dataset_pd,user, item, timestamp)\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 309708\n",
            "Test size: 49424\n"
          ]
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "id": "ce079817",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:51.882961Z",
          "start_time": "2025-07-12T13:58:50.882539Z"
        },
        "id": "ce079817"
      },
      "source": [
        "# maintain a map from new id to old id, new id for constructing matrix\n",
        "user2id = {u: i for i, u in enumerate(dataset_pd[user].unique())}\n",
        "item2id = {i: j for j, i in enumerate(dataset_pd[item].unique())}\n",
        "\n",
        "# apply to train_df and test_df\n",
        "train_df[user_id] = train_df[user].map(user2id)\n",
        "train_df[item_id] = train_df[item].map(item2id)\n",
        "test_df[user_id] = test_df[user].map(user2id)\n",
        "test_df[item_id] = test_df[item].map(item2id)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "id": "a7aba75c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:51.926849Z",
          "start_time": "2025-07-12T13:58:51.911489Z"
        },
        "id": "a7aba75c"
      },
      "source": [
        "# DSSM implementation in PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "class DSSM(nn.Module):\n",
        "    \"\"\"\n",
        "    ÂèåÂ°î DSSMÔºöÁî®Êà∑Â°î + Áâ©ÂìÅÂ°î\n",
        "    hidden_dims Â¶Ç [128, 64]ÔºåÊúÄÂêéËæìÂá∫Áª¥Â∫¶ = hidden_dims[-1]\n",
        "    \"\"\"\n",
        "    def __init__(self, num_users, num_items, emb_dim=128, mlp_hidden_size=[128, 64, 32], dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_dim)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_dim)\n",
        "\n",
        "        # üî∏ ÂàùÂßãÂåñÔºàÂèØÈÄâ‰ΩÜÊé®ËçêÔºâ\n",
        "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
        "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
        "                # ÊûÑÂª∫ MLP Â±Ç\n",
        "        self.mlp_user = self.build_mlp(emb_dim, mlp_hidden_size, dropout)\n",
        "        self.mlp_item = self.build_mlp(emb_dim, mlp_hidden_size, dropout)\n",
        "\n",
        "    def build_mlp(self, input_dim, hidden_sizes, dropout):\n",
        "          layers = []\n",
        "          for h in hidden_sizes:\n",
        "            layers.append(nn.Linear(input_dim, h))\n",
        "            layers.append(nn.BatchNorm1d(h))\n",
        "            layers.append(nn.Tanh())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "            input_dim = h\n",
        "          return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, user_id, item_id, l2_norm=True):\n",
        "        \"\"\"\n",
        "        ËøîÂõû:\n",
        "          score: (B,) ÁÇπÁßØÂàÜÊï∞\n",
        "          u_vec, i_vec: (B, d) ‰∏§‰æßÂêëÈáè\n",
        "        \"\"\"\n",
        "        u = self.user_emb(user_id)          # (B, emb_dim)\n",
        "        i = self.item_emb(item_id)          # (B, emb_dim)\n",
        "\n",
        "        u_vec = self.mlp_user(u)            # (B, d)\n",
        "        i_vec = self.mlp_item(i)            # (B, d)\n",
        "\n",
        "        if l2_norm:\n",
        "            u_vec = F.normalize(u_vec, p=2, dim=1)\n",
        "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
        "\n",
        "        score = (u_vec * i_vec).sum(dim=1)  # (B,)\n",
        "        return score, u_vec, i_vec\n",
        "    def get_users_embedding(self,user_ids,l2_norm=True):\n",
        "        u = self.user_emb(user_ids)          # (B, emb_dim)\n",
        "\n",
        "        u_vec = self.mlp_user(u)            # (B, d)\n",
        "\n",
        "        if l2_norm:\n",
        "            u_vec = F.normalize(u_vec, p=2, dim=1)\n",
        "        return u_vec\n",
        "    def get_items_embedding(self,item_ids,l2_norm=True):\n",
        "        i = self.item_emb(item_ids)          # (B, emb_dim)\n",
        "\n",
        "        i_vec = self.mlp_item(i)            # (B, d)\n",
        "\n",
        "        if l2_norm:\n",
        "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
        "        return i_vec\n",
        "\n",
        "    def save_embeddings(self, num_users, num_items, device, save_dir='./embeddings'):\n",
        "        import os\n",
        "        import faiss\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        self.eval()\n",
        "        self.to(device)\n",
        "\n",
        "        user_ids = torch.arange(num_users, dtype=torch.long, device=device)\n",
        "        item_ids = torch.arange(num_items, dtype=torch.long, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            user_embeds = self.get_users_embedding(user_ids, l2_norm=True)\n",
        "            item_embeds = self.get_items_embedding(item_ids, l2_norm=True)\n",
        "\n",
        "        user_embeds = user_embeds.cpu().numpy().astype(np.float32)\n",
        "        item_embeds = item_embeds.cpu().numpy().astype(np.float32)\n",
        "\n",
        "        # ‰øùÂ≠òÂêëÈáè\n",
        "        np.save(f\"{save_dir}/user_embeddings.npy\", user_embeds)\n",
        "        np.save(f\"{save_dir}/item_embeddings.npy\", item_embeds)\n",
        "\n",
        "        # ÊûÑÂª∫ FAISS indexÔºà‰ΩøÁî®ÂÜÖÁßØÔºâ\n",
        "        dim = item_embeds.shape[1]\n",
        "        index = faiss.IndexFlatIP(dim)\n",
        "        index.add(item_embeds)\n",
        "\n",
        "        faiss.write_index(index, f\"{save_dir}/item_index.faiss\")\n",
        "        print(\"Saved user/item embeddings and FAISS index.\")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "id": "07e268c2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T13:58:51.967812Z",
          "start_time": "2025-07-12T13:58:51.955879Z"
        },
        "id": "07e268c2"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from datetime import datetime\n",
        "\n",
        "def train_model(model,\n",
        "                                train_df,\n",
        "                                epochs=10,\n",
        "                                batch_size=64,\n",
        "                                lr=1e-3,\n",
        "                                print_every=1,\n",
        "                                num_items=num_items,\n",
        "                                device=None):\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # ‰Ω†ÈúÄË¶Å‰∏Ä‰∏™ data_loader ËøîÂõû (user_id, pos_item_id) ÂØπÔºåÊó†Ë¥üÊ†∑Êú¨\n",
        "    train_loader = customdataset.build_train_loader_inbatch(train_df, batch_size=batch_size,user_col=user_id, item_col=item_id)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        dt_start = datetime.now()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            user_ids, pos_item_ids = batch\n",
        "            user_ids = user_ids.to(device)\n",
        "            pos_item_ids = pos_item_ids.to(device)\n",
        "\n",
        "            # 1. ÂâçÂêë‰º†Êí≠ÔºàËøîÂõû user / item ÂêëÈáèÔºâ\n",
        "            _, u_vec, _ = model(user_ids, pos_item_ids, l2_norm=False)\n",
        "            _, _, i_vec = model(user_ids, pos_item_ids, l2_norm=False)\n",
        "\n",
        "            # 2. ÂæóÂàÜÁü©ÈòµÔºöÊØè‰∏™ user ÂØπÊâÄÊúâÊ≠£ item ÁöÑÊâìÂàÜ\n",
        "            logits = torch.matmul(u_vec, i_vec.T)  # shape: (B, B)\n",
        "\n",
        "            # 3. ÊûÑÈÄ†Ê†áÁ≠æÔºöÊØè‰∏™ user ÁöÑÊ≠£Á°Æ item Âú®ÂØπËßíÁ∫øÔºàÂç≥‰ΩçÁΩÆ iÔºâ\n",
        "            labels = torch.arange(logits.size(0), device=device)  # [0, 1, ..., B-1]\n",
        "\n",
        "            # 4. Cross Entropy Loss\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "            # 5. ÂèçÂêë‰º†Êí≠\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Êó•Âøó\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        dt_end = datetime.now()\n",
        "        dt = dt_end - dt_start\n",
        "\n",
        "        print(f\"[Epoch {epoch:02d}/{epochs}] avg InBatch Softmax Loss = {avg_loss:.4f}, time = {dt.total_seconds():.2f}s\")\n",
        "\n",
        "    return\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "id": "cd29a40c68841c9c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:54.878124Z",
          "start_time": "2025-07-12T13:58:51.995794Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd29a40c68841c9c",
        "outputId": "8bfd79d6-87f8-4310-c7f0-c11d95c0d090"
      },
      "source": [
        "model = DSSM(num_users,num_items,emb_dim=64)\n",
        "model.to(device)\n",
        "train_model(model=model,epochs=100, train_df=train_df,num_items=num_items,batch_size=1024)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01/100] avg InBatch Softmax Loss = 8.2708, time = 2.34s\n",
            "[Epoch 02/100] avg InBatch Softmax Loss = 7.4547, time = 2.14s\n",
            "[Epoch 03/100] avg InBatch Softmax Loss = 7.1302, time = 2.10s\n",
            "[Epoch 04/100] avg InBatch Softmax Loss = 6.9908, time = 2.05s\n",
            "[Epoch 05/100] avg InBatch Softmax Loss = 6.9113, time = 2.10s\n",
            "[Epoch 06/100] avg InBatch Softmax Loss = 6.7626, time = 2.01s\n",
            "[Epoch 07/100] avg InBatch Softmax Loss = 6.5783, time = 2.10s\n",
            "[Epoch 08/100] avg InBatch Softmax Loss = 6.3890, time = 2.05s\n",
            "[Epoch 09/100] avg InBatch Softmax Loss = 6.1857, time = 1.98s\n",
            "[Epoch 10/100] avg InBatch Softmax Loss = 5.9877, time = 2.00s\n",
            "[Epoch 11/100] avg InBatch Softmax Loss = 5.8174, time = 2.05s\n",
            "[Epoch 12/100] avg InBatch Softmax Loss = 5.6780, time = 2.04s\n",
            "[Epoch 13/100] avg InBatch Softmax Loss = 5.5756, time = 2.15s\n",
            "[Epoch 14/100] avg InBatch Softmax Loss = 5.5001, time = 2.02s\n",
            "[Epoch 15/100] avg InBatch Softmax Loss = 5.4365, time = 1.96s\n",
            "[Epoch 16/100] avg InBatch Softmax Loss = 5.3872, time = 2.03s\n",
            "[Epoch 17/100] avg InBatch Softmax Loss = 5.3418, time = 1.99s\n",
            "[Epoch 18/100] avg InBatch Softmax Loss = 5.3048, time = 1.99s\n",
            "[Epoch 19/100] avg InBatch Softmax Loss = 5.2714, time = 2.01s\n",
            "[Epoch 20/100] avg InBatch Softmax Loss = 5.2421, time = 1.99s\n",
            "[Epoch 21/100] avg InBatch Softmax Loss = 5.2142, time = 2.00s\n",
            "[Epoch 22/100] avg InBatch Softmax Loss = 5.1880, time = 1.98s\n",
            "[Epoch 23/100] avg InBatch Softmax Loss = 5.1657, time = 1.96s\n",
            "[Epoch 24/100] avg InBatch Softmax Loss = 5.1412, time = 1.95s\n",
            "[Epoch 25/100] avg InBatch Softmax Loss = 5.1232, time = 2.00s\n",
            "[Epoch 26/100] avg InBatch Softmax Loss = 5.1037, time = 2.00s\n",
            "[Epoch 27/100] avg InBatch Softmax Loss = 5.0860, time = 1.95s\n",
            "[Epoch 28/100] avg InBatch Softmax Loss = 5.0699, time = 2.06s\n",
            "[Epoch 29/100] avg InBatch Softmax Loss = 5.0527, time = 1.97s\n",
            "[Epoch 30/100] avg InBatch Softmax Loss = 5.0409, time = 2.01s\n",
            "[Epoch 31/100] avg InBatch Softmax Loss = 5.0260, time = 2.09s\n",
            "[Epoch 32/100] avg InBatch Softmax Loss = 5.0136, time = 2.04s\n",
            "[Epoch 33/100] avg InBatch Softmax Loss = 5.0019, time = 1.96s\n",
            "[Epoch 34/100] avg InBatch Softmax Loss = 4.9914, time = 1.96s\n",
            "[Epoch 35/100] avg InBatch Softmax Loss = 4.9827, time = 2.00s\n",
            "[Epoch 36/100] avg InBatch Softmax Loss = 4.9723, time = 1.96s\n",
            "[Epoch 37/100] avg InBatch Softmax Loss = 4.9638, time = 2.04s\n",
            "[Epoch 38/100] avg InBatch Softmax Loss = 4.9546, time = 2.00s\n",
            "[Epoch 39/100] avg InBatch Softmax Loss = 4.9495, time = 2.02s\n",
            "[Epoch 40/100] avg InBatch Softmax Loss = 4.9377, time = 1.97s\n",
            "[Epoch 41/100] avg InBatch Softmax Loss = 4.9277, time = 1.96s\n",
            "[Epoch 42/100] avg InBatch Softmax Loss = 4.9215, time = 1.94s\n",
            "[Epoch 43/100] avg InBatch Softmax Loss = 4.9169, time = 1.97s\n",
            "[Epoch 44/100] avg InBatch Softmax Loss = 4.9063, time = 2.05s\n",
            "[Epoch 45/100] avg InBatch Softmax Loss = 4.9000, time = 1.96s\n",
            "[Epoch 46/100] avg InBatch Softmax Loss = 4.8941, time = 1.98s\n",
            "[Epoch 47/100] avg InBatch Softmax Loss = 4.8882, time = 2.03s\n",
            "[Epoch 48/100] avg InBatch Softmax Loss = 4.8802, time = 1.99s\n",
            "[Epoch 49/100] avg InBatch Softmax Loss = 4.8752, time = 2.00s\n",
            "[Epoch 50/100] avg InBatch Softmax Loss = 4.8644, time = 2.08s\n",
            "[Epoch 51/100] avg InBatch Softmax Loss = 4.8571, time = 1.96s\n",
            "[Epoch 52/100] avg InBatch Softmax Loss = 4.8469, time = 1.99s\n",
            "[Epoch 53/100] avg InBatch Softmax Loss = 4.8405, time = 1.97s\n",
            "[Epoch 54/100] avg InBatch Softmax Loss = 4.8344, time = 1.97s\n",
            "[Epoch 55/100] avg InBatch Softmax Loss = 4.8264, time = 1.97s\n",
            "[Epoch 56/100] avg InBatch Softmax Loss = 4.8181, time = 2.02s\n",
            "[Epoch 57/100] avg InBatch Softmax Loss = 4.8095, time = 2.02s\n",
            "[Epoch 58/100] avg InBatch Softmax Loss = 4.8048, time = 1.92s\n",
            "[Epoch 59/100] avg InBatch Softmax Loss = 4.7981, time = 1.96s\n",
            "[Epoch 60/100] avg InBatch Softmax Loss = 4.7923, time = 1.96s\n",
            "[Epoch 61/100] avg InBatch Softmax Loss = 4.7870, time = 1.93s\n",
            "[Epoch 62/100] avg InBatch Softmax Loss = 4.7812, time = 2.01s\n",
            "[Epoch 63/100] avg InBatch Softmax Loss = 4.7752, time = 2.07s\n",
            "[Epoch 64/100] avg InBatch Softmax Loss = 4.7717, time = 1.95s\n",
            "[Epoch 65/100] avg InBatch Softmax Loss = 4.7657, time = 1.99s\n",
            "[Epoch 66/100] avg InBatch Softmax Loss = 4.7626, time = 1.96s\n",
            "[Epoch 67/100] avg InBatch Softmax Loss = 4.7574, time = 1.96s\n",
            "[Epoch 68/100] avg InBatch Softmax Loss = 4.7525, time = 1.97s\n",
            "[Epoch 69/100] avg InBatch Softmax Loss = 4.7461, time = 2.10s\n",
            "[Epoch 70/100] avg InBatch Softmax Loss = 4.7417, time = 1.96s\n",
            "[Epoch 71/100] avg InBatch Softmax Loss = 4.7358, time = 1.95s\n",
            "[Epoch 72/100] avg InBatch Softmax Loss = 4.7289, time = 1.98s\n",
            "[Epoch 73/100] avg InBatch Softmax Loss = 4.7322, time = 1.98s\n",
            "[Epoch 74/100] avg InBatch Softmax Loss = 4.7247, time = 2.05s\n",
            "[Epoch 75/100] avg InBatch Softmax Loss = 4.7172, time = 2.06s\n",
            "[Epoch 76/100] avg InBatch Softmax Loss = 4.7168, time = 1.96s\n",
            "[Epoch 77/100] avg InBatch Softmax Loss = 4.7112, time = 1.96s\n",
            "[Epoch 78/100] avg InBatch Softmax Loss = 4.7098, time = 1.99s\n",
            "[Epoch 79/100] avg InBatch Softmax Loss = 4.7021, time = 2.03s\n",
            "[Epoch 80/100] avg InBatch Softmax Loss = 4.6978, time = 1.94s\n",
            "[Epoch 81/100] avg InBatch Softmax Loss = 4.6909, time = 2.03s\n",
            "[Epoch 82/100] avg InBatch Softmax Loss = 4.6916, time = 2.02s\n",
            "[Epoch 83/100] avg InBatch Softmax Loss = 4.6815, time = 1.93s\n",
            "[Epoch 84/100] avg InBatch Softmax Loss = 4.6776, time = 2.02s\n",
            "[Epoch 85/100] avg InBatch Softmax Loss = 4.6706, time = 2.00s\n",
            "[Epoch 86/100] avg InBatch Softmax Loss = 4.6695, time = 2.01s\n",
            "[Epoch 87/100] avg InBatch Softmax Loss = 4.6612, time = 2.02s\n",
            "[Epoch 88/100] avg InBatch Softmax Loss = 4.6541, time = 1.99s\n",
            "[Epoch 89/100] avg InBatch Softmax Loss = 4.6484, time = 2.00s\n",
            "[Epoch 90/100] avg InBatch Softmax Loss = 4.6465, time = 2.05s\n",
            "[Epoch 91/100] avg InBatch Softmax Loss = 4.6407, time = 2.03s\n",
            "[Epoch 92/100] avg InBatch Softmax Loss = 4.6321, time = 2.00s\n",
            "[Epoch 93/100] avg InBatch Softmax Loss = 4.6254, time = 2.08s\n",
            "[Epoch 94/100] avg InBatch Softmax Loss = 4.6238, time = 2.04s\n",
            "[Epoch 95/100] avg InBatch Softmax Loss = 4.6147, time = 1.94s\n",
            "[Epoch 96/100] avg InBatch Softmax Loss = 4.6127, time = 1.98s\n",
            "[Epoch 97/100] avg InBatch Softmax Loss = 4.6059, time = 2.02s\n",
            "[Epoch 98/100] avg InBatch Softmax Loss = 4.6025, time = 1.97s\n",
            "[Epoch 99/100] avg InBatch Softmax Loss = 4.5969, time = 2.09s\n",
            "[Epoch 100/100] avg InBatch Softmax Loss = 4.5895, time = 1.99s\n"
          ]
        }
      ],
      "execution_count": 48
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:55.008421Z",
          "start_time": "2025-07-12T14:01:54.939903Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "848b63e397b62c61",
        "outputId": "860e9089-cb0f-4efd-e278-75610860ee79"
      },
      "cell_type": "code",
      "source": [
        "model.save_embeddings(num_users=num_users,num_items=num_items,device=device,save_dir=save_dir)"
      ],
      "id": "848b63e397b62c61",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved user/item embeddings and FAISS index.\n"
          ]
        }
      ],
      "execution_count": 49
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:55.022942Z",
          "start_time": "2025-07-12T14:01:55.015944Z"
        },
        "id": "25398aa2359bb59a"
      },
      "cell_type": "code",
      "source": [
        "def hit_rate_at_k(ranked_list, true_item):\n",
        "    return int(true_item in ranked_list)"
      ],
      "id": "25398aa2359bb59a",
      "outputs": [],
      "execution_count": 50
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:55.088537Z",
          "start_time": "2025-07-12T14:01:55.082268Z"
        },
        "id": "e836833fc9dd8385"
      },
      "cell_type": "code",
      "source": [
        "def ndcg_at_k(ranked_list, true_item):\n",
        "    if true_item in ranked_list:\n",
        "        index = ranked_list.index(true_item)\n",
        "        return 1 / np.log2(index + 2)\n",
        "    else:\n",
        "        return 0.0"
      ],
      "id": "e836833fc9dd8385",
      "outputs": [],
      "execution_count": 51
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:55.101683Z",
          "start_time": "2025-07-12T14:01:55.094548Z"
        },
        "id": "a784ef14493efab3"
      },
      "cell_type": "code",
      "source": [
        "def evaluate_random(test_loader, item_pool, top_k=10):\n",
        "    hits, ndcgs = [], []\n",
        "    for _, item_batch in test_loader:\n",
        "        item_batch = item_batch.numpy()\n",
        "        for true_item in item_batch:\n",
        "            # ‰ªéÂÖ®‰ΩìÁâ©ÂìÅ‰∏≠ÈöèÊú∫ÊäΩ top_k ‰∏™ÔºàÂåÖÂê´Êàñ‰∏çÂåÖÂê´ true_itemÔºâ\n",
        "            rec_list = random.sample(item_pool, top_k)\n",
        "            hits.append(hit_rate_at_k(rec_list, true_item))\n",
        "            ndcgs.append(ndcg_at_k(rec_list, true_item))\n",
        "    return np.mean(hits), np.mean(ndcgs)\n"
      ],
      "id": "a784ef14493efab3",
      "outputs": [],
      "execution_count": 52
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:55.139911Z",
          "start_time": "2025-07-12T14:01:55.131997Z"
        },
        "id": "2fd356468126edd2"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_popular(test_loader, train_df, top_k=10):\n",
        "    item_counts = Counter(train_df['item_id'].values)\n",
        "    popular_items = [item for item, _ in item_counts.most_common(top_k)]\n",
        "\n",
        "    hits, ndcgs = [], []\n",
        "    for _, item_batch in test_loader:\n",
        "        item_batch = item_batch.numpy()\n",
        "        for true_item in item_batch:\n",
        "            hits.append(hit_rate_at_k(popular_items, true_item))\n",
        "            ndcgs.append(ndcg_at_k(popular_items, true_item))\n",
        "    return np.mean(hits), np.mean(ndcgs)"
      ],
      "id": "2fd356468126edd2",
      "outputs": [],
      "execution_count": 53
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:01:55.180169Z",
          "start_time": "2025-07-12T14:01:55.170652Z"
        },
        "id": "bd73712d1405d906"
      },
      "cell_type": "code",
      "source": [
        "def evaluate_model(test_loader, model, faiss_index, device, top_k=10):\n",
        "    hits, ndcgs = [], []\n",
        "    model.eval()\n",
        "\n",
        "    for user_batch, item_batch in test_loader:\n",
        "        user_batch = user_batch.to(device)\n",
        "        item_batch = item_batch.cpu().numpy()  # true items\n",
        "\n",
        "        with torch.no_grad():\n",
        "            user_vecs = model.get_users_embedding(user_batch)\n",
        "            user_vecs = user_vecs.cpu().numpy().astype(np.float32)\n",
        "\n",
        "        # FAISS ÊâπÈáè topK\n",
        "        _, I = faiss_index.search(user_vecs, top_k)  # (B, K)\n",
        "        topk_lists = I.tolist()\n",
        "\n",
        "        for rec_list, true_item in zip(topk_lists, item_batch):\n",
        "            hits.append(hit_rate_at_k(rec_list, true_item))\n",
        "            ndcgs.append(ndcg_at_k(rec_list, true_item))\n",
        "\n",
        "    return np.mean(hits), np.mean(ndcgs)"
      ],
      "id": "bd73712d1405d906",
      "outputs": [],
      "execution_count": 54
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:02:03.509536Z",
          "start_time": "2025-07-12T14:01:55.208715Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d626cca926d2732f",
        "outputId": "e7f247a9-85e2-4aab-c333-de60afd8875f"
      },
      "cell_type": "code",
      "source": [
        "test_loader = customdataset.build_test_loader(test_df, num_items ,user_col = user_id, item_col = item_id, batch_size=1024, num_workers=num_workers)\n",
        "item_pool = list(range(num_items))\n",
        "faiss_index = faiss.read_index(f\"{save_dir}/item_index.faiss\")\n",
        "\n",
        "hr_r, ndcg_r = evaluate_random(test_loader, item_pool ,top_k=top_k)\n",
        "\n",
        "print(f\"Random HR@{top_k} = {hr_r:.4f}, nDCG@{top_k} = {ndcg_r:.4f}\")\n"
      ],
      "id": "d626cca926d2732f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random HR@10 = 0.0004, nDCG@10 = 0.0001\n"
          ]
        }
      ],
      "execution_count": 55
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:02:11.793103Z",
          "start_time": "2025-07-12T14:02:03.541546Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8be6dec3309abad7",
        "outputId": "4bec2bc0-9e17-465a-e948-d180d1b42932"
      },
      "cell_type": "code",
      "source": [
        "hr_p, ndcg_p = evaluate_popular(test_loader, train_df,top_k=top_k)\n",
        "print(f\"Popular HR@{top_k} = {hr_p:.4f}, nDCG@{top_k} = {ndcg_p:.4f}\")\n"
      ],
      "id": "8be6dec3309abad7",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Popular HR@10 = 0.0029, nDCG@10 = 0.0014\n"
          ]
        }
      ],
      "execution_count": 56
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-12T14:02:26.356147Z",
          "start_time": "2025-07-12T14:02:11.828289Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "744d21ae291f0a70",
        "outputId": "16232805-2bf1-414f-b6a6-5c8ded63d97d"
      },
      "cell_type": "code",
      "source": [
        "hr_m, ndcg_m = evaluate_model(test_loader, model, faiss_index, device,top_k=top_k)\n",
        "print(f\"Model   HR@{top_k} = {hr_m:.4f}, nDCG@{top_k} = {ndcg_m:.4f}\")\n"
      ],
      "id": "744d21ae291f0a70",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model   HR@10 = 0.0243, nDCG@10 = 0.0103\n"
          ]
        }
      ],
      "execution_count": 57
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}