{
 "cells": [
  {
   "cell_type": "code",
   "id": "b828e981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:42.901731Z",
     "start_time": "2025-06-30T17:31:34.168345Z"
    }
   },
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from networkx.readwrite.json_graph import adjacency"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e99a31348e0a553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:42.953543Z",
     "start_time": "2025-06-30T17:31:42.911322Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "76a2087d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:43.783596Z",
     "start_time": "2025-06-30T17:31:43.643664Z"
    }
   },
   "source": [
    "dataset_pd = pd.read_csv('D:\\\\VideoRecSystem\\\\MicroLens\\\\DataSet\\\\MicroLens-50k_pairs.csv')\n",
    "# dataset_pd = pd.read_csv('MicroLens-50k_pairs.csv')"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "943fc6c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:43.818884Z",
     "start_time": "2025-06-30T17:31:43.801920Z"
    }
   },
   "source": [
    "dataset_pd.head(10)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    user   item      timestamp\n",
       "0  36121   9580  1583378629552\n",
       "1  26572   9580  1583436719018\n",
       "2  37550   9580  1584412681021\n",
       "3  14601   9580  1584848802432\n",
       "4  15061   9580  1585388171106\n",
       "5   6364   9580  1585390736041\n",
       "6   3542   9580  1585404918503\n",
       "7  21038   9580  1590144594477\n",
       "8  12538  14631  1634867362929\n",
       "9  47592  14631  1634872254913"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36121</td>\n",
       "      <td>9580</td>\n",
       "      <td>1583378629552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26572</td>\n",
       "      <td>9580</td>\n",
       "      <td>1583436719018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37550</td>\n",
       "      <td>9580</td>\n",
       "      <td>1584412681021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14601</td>\n",
       "      <td>9580</td>\n",
       "      <td>1584848802432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15061</td>\n",
       "      <td>9580</td>\n",
       "      <td>1585388171106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6364</td>\n",
       "      <td>9580</td>\n",
       "      <td>1585390736041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3542</td>\n",
       "      <td>9580</td>\n",
       "      <td>1585404918503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21038</td>\n",
       "      <td>9580</td>\n",
       "      <td>1590144594477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12538</td>\n",
       "      <td>14631</td>\n",
       "      <td>1634867362929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>47592</td>\n",
       "      <td>14631</td>\n",
       "      <td>1634872254913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "69160caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:43.888236Z",
     "start_time": "2025-06-30T17:31:43.878771Z"
    }
   },
   "source": [
    "dataset_pd.count"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of          user   item      timestamp\n",
       "0       36121   9580  1583378629552\n",
       "1       26572   9580  1583436719018\n",
       "2       37550   9580  1584412681021\n",
       "3       14601   9580  1584848802432\n",
       "4       15061   9580  1585388171106\n",
       "...       ...    ...            ...\n",
       "359703  48702   1363  1662984066647\n",
       "359704  27203   7291  1662984082974\n",
       "359705  29261  19649  1662984103874\n",
       "359706  28341  19188  1662984123833\n",
       "359707  38967   7254  1662984132429\n",
       "\n",
       "[359708 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "6d42c375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:43.994396Z",
     "start_time": "2025-06-30T17:31:43.962484Z"
    }
   },
   "source": [
    "user_counts = dataset_pd['user'].value_counts()\n",
    "item_counts = dataset_pd['item'].value_counts()\n",
    "# valid_users = user_counts[user_counts > 3].index\n",
    "# valid_items = item_counts[item_counts > 3].index\n",
    "# filtered_df = dataset_pd[dataset_pd['user'].isin(valid_users) & dataset_pd['item'].isin(valid_items)]\n",
    "# filtered_df.count"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "8b8ae0c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:44.178267Z",
     "start_time": "2025-06-30T17:31:44.026758Z"
    }
   },
   "source": [
    "# order by user,timestamp \n",
    "filtered_df = dataset_pd.sort_values(by=[\"user\", \"timestamp\"])\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "2d2d4de256fd88a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:44.199814Z",
     "start_time": "2025-06-30T17:31:44.192815Z"
    }
   },
   "source": [
    "def split(df, user_col='user', item_col='item', time_col='timestamp'):\n",
    "\n",
    "    df = df.sort_values(by=[user_col, time_col])  # 按用户时间排序\n",
    "\n",
    "    # 获取每个用户的最后一条记录作为 test\n",
    "    test_df = df.groupby(user_col).tail(1)\n",
    "    train_df = df.drop(index=test_df.index)\n",
    "\n",
    "    # 过滤 test 中那些 user/item 不在 train 中的\n",
    "    train_users = set(train_df[user_col])\n",
    "    train_items = set(train_df[item_col])\n",
    "\n",
    "    test_df = test_df[\n",
    "        test_df[user_col].isin(train_users) &\n",
    "        test_df[item_col].isin(train_items)\n",
    "    ]\n",
    "\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3db1146761e45165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:44.661492Z",
     "start_time": "2025-06-30T17:31:44.215744Z"
    }
   },
   "source": [
    "\n",
    "train_df, test_df = split(filtered_df,user_col='user', item_col='item', time_col='timestamp')\n",
    "\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 309708\n",
      "Test size: 49424\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "ce079817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:45.695431Z",
     "start_time": "2025-06-30T17:31:44.693404Z"
    }
   },
   "source": [
    "# main tain a map from new id to old id, new id for constructing matrix\n",
    "user2id = {u: i for i, u in enumerate(filtered_df['user'].unique())}\n",
    "item2id = {i: j for j, i in enumerate(filtered_df['item'].unique())}\n",
    "\n",
    "# apply to train_df and test_df\n",
    "train_df['user_id'] = train_df['user'].map(user2id)\n",
    "train_df['item_id'] = train_df['item'].map(item2id)\n",
    "test_df['user_id'] = test_df['user'].map(user2id)\n",
    "test_df['item_id'] = test_df['item'].map(item2id)\n",
    "\n",
    "num_users = len(user2id)\n",
    "num_items = len(item2id)\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "d94d1a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:45.739703Z",
     "start_time": "2025-06-30T17:31:45.707015Z"
    }
   },
   "source": [
    "\n",
    "# ========== Load cover_emb128.lmdb and build cover_matrix ==========\n",
    "\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def _decode_key(key_bytes: bytes) -> int:\n",
    "    # Assume key stored as ascii string of integer\n",
    "    return int(key_bytes.decode('ascii'))\n",
    "\n",
    "def load_cover_matrix(lmdb_path: str, num_items: int, vector_dim: int = 128, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    加载封面向量 LMDB，key 从 1 到 num_items，对应行号。\n",
    "    第 0 行保留为 padding，全 0。\n",
    "\n",
    "    返回:\n",
    "        np.ndarray, shape = (num_items + 1, vector_dim)\n",
    "    \"\"\"\n",
    "    import lmdb\n",
    "    import numpy as np\n",
    "\n",
    "    mat = np.zeros((num_items + 1, vector_dim), dtype=dtype)  # index 0 is reserved padding\n",
    "    env = lmdb.open(lmdb_path, readonly=True, subdir=False, lock=False, readahead=False)\n",
    "\n",
    "    with env.begin() as txn:\n",
    "        for idx in range(1, num_items + 1):\n",
    "            key = str(idx).encode()\n",
    "            val = txn.get(key)\n",
    "            if val is None:\n",
    "                continue\n",
    "            vec = np.frombuffer(val, dtype=dtype)\n",
    "            if vec.size != vector_dim:\n",
    "                raise ValueError(f\"Item {idx} vector dim {vec.size} != {vector_dim}\")\n",
    "            mat[idx] = vec\n",
    "\n",
    "    env.close()\n",
    "    return mat\n",
    "\n",
    "# ----- Path to LMDB -----\n",
    "lmdb_path = r\"D:/VideoRecSystem/MicroLens/cover_emb128.lmdb\"\n",
    "cover_matrix = load_cover_matrix(lmdb_path, num_items=num_items, vector_dim=128)\n",
    "print('cover_matrix shape:', cover_matrix.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover_matrix shape: (19221, 128)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6f235b3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:45.813496Z",
     "start_time": "2025-06-30T17:31:45.801152Z"
    }
   },
   "source": [
    "\n",
    "# DSSM implementation that directly concatenates ID embedding with cover embedding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DSSM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        id_emb_dim: int,\n",
    "        cover_matrix,\n",
    "        hidden_dims=(128, 64),\n",
    "        dropout: float = 0.2,\n",
    "        padding_idx: int = 0,\n",
    "        freeze_cover: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # User ID embedding\n",
    "        self.user_emb = nn.Embedding(num_users + 1, id_emb_dim, padding_idx=padding_idx)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "\n",
    "        # Item ID embedding\n",
    "        self.item_id_emb = nn.Embedding(num_items + 1, id_emb_dim, padding_idx=padding_idx)\n",
    "        nn.init.xavier_uniform_(self.item_id_emb.weight)\n",
    "\n",
    "        # Cover embedding lookup\n",
    "        cover_tensor = torch.tensor(cover_matrix, dtype=torch.float32)\n",
    "        self.cover_emb = nn.Embedding.from_pretrained(\n",
    "            cover_tensor,\n",
    "            freeze=freeze_cover,\n",
    "            padding_idx=padding_idx\n",
    "        )\n",
    "        self.item_input_dim = id_emb_dim + cover_tensor.shape[1]\n",
    "\n",
    "        def mlp_block(in_dim):\n",
    "            layers = []\n",
    "            for h in hidden_dims:\n",
    "                layers.append(nn.Linear(in_dim, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "                in_dim = h\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.mlp_user = mlp_block(id_emb_dim)\n",
    "        self.mlp_item = mlp_block(self.item_input_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, l2_norm: bool = True):\n",
    "        u_emb = self.user_emb(user_ids)\n",
    "        id_vec = self.item_id_emb(item_ids)\n",
    "        cover_vec = self.cover_emb(item_ids)\n",
    "        i_emb = torch.cat([id_vec, cover_vec], dim=-1)\n",
    "\n",
    "        u_vec = self.mlp_user(u_emb)\n",
    "        i_vec = self.mlp_item(i_emb)\n",
    "\n",
    "        if l2_norm:\n",
    "            u_vec = F.normalize(u_vec, p=2, dim=1)\n",
    "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
    "\n",
    "        score = (u_vec * i_vec).sum(dim=1)\n",
    "        return score, u_vec, i_vec\n",
    "    def get_item_vec(self, item_ids):\n",
    "        id_vec = self.item_id_emb(item_ids)\n",
    "        cover_vec = self.cover_emb(item_ids)\n",
    "        combined = torch.cat([id_vec, cover_vec], dim=-1)\n",
    "        return self.mlp_item(combined)\n",
    "    def get_embedding(self, user_id, item_id):\n",
    "        return self.forward(user_id, item_id)[0]\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "f21704ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:45.826031Z",
     "start_time": "2025-06-30T17:31:45.819506Z"
    }
   },
   "source": [
    "# -----------------------------------------------------------\n",
    "# bpr_loss: 直接接受分数，内部求 mean，返回标量 Tensor\n",
    "# -----------------------------------------------------------\n",
    "def bpr_loss(pos_scores, neg_scores):\n",
    "    \"\"\"\n",
    "    pos_scores, neg_scores: shape = (B,)\n",
    "    返回标量 Tensor\n",
    "    \"\"\"\n",
    "    return -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "503d8f70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:47.432105Z",
     "start_time": "2025-06-30T17:31:45.883720Z"
    }
   },
   "source": [
    "# Negative sampling function\n",
    "users = train_df['user_id'].unique()\n",
    "user_pos_dict = train_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "\n",
    "def sample_batch(num_items, batch_size):\n",
    "\n",
    "    batch_users = np.random.choice(users, size=batch_size)\n",
    "\n",
    "    user_ids, pos_ids, neg_ids = [], [], []\n",
    "    for u in batch_users:\n",
    "        pos_items = list(user_pos_dict[u])\n",
    "        pos = random.choice(pos_items)\n",
    "        while True:\n",
    "            neg = random.randint(0, num_items - 1)\n",
    "            if neg not in user_pos_dict[u]:\n",
    "                break\n",
    "        user_ids.append(u)\n",
    "        pos_ids.append(pos)\n",
    "        neg_ids.append(neg)\n",
    "\n",
    "    return torch.LongTensor(user_ids), torch.LongTensor(pos_ids), torch.LongTensor(neg_ids)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "07e268c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:47.486226Z",
     "start_time": "2025-06-30T17:31:47.467610Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# --------- 采样函数保持不变 (示意) ------------\n",
    "# def sample_batch(train_df, num_items, batch_size): ...\n",
    "\n",
    "# --------- BPR 损失保持不变 -------------------\n",
    "# def bpr_loss(user_vec, pos_vec, neg_vec): ...\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "def train_model(model,\n",
    "                train_df,\n",
    "                num_items,\n",
    "                epochs=10,\n",
    "                batch_size=1024,\n",
    "                lr=1e-3,\n",
    "                print_every=1,\n",
    "                max_grad_norm=None,\n",
    "                device=None):\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()         # train model\n",
    "\n",
    "        # —— epoch 内建议跑多个 mini-batch ——\n",
    "        #   下面示例：每个 epoch 跑 len(train_df)//batch_size 个 batch\n",
    "        num_steps = max(1, len(train_df) // batch_size)\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        for _ in range(num_steps):\n",
    "            # 1.负采样\n",
    "            user_ids, pos_ids, neg_ids = sample_batch( num_items, batch_size)\n",
    "\n",
    "            # 2.搬设备\n",
    "            user_ids = user_ids.to(device)   # 已经是 LongTensor\n",
    "            pos_ids  = pos_ids.to(device)\n",
    "            neg_ids  = neg_ids.to(device)\n",
    "\n",
    "            # 只跑一次 user 塔\n",
    "            u_vec = model.mlp_user(model.user_emb(user_ids))          # (B,d)\n",
    "            pos_vec = model.get_item_vec(pos_ids)\n",
    "            neg_vec = model.get_item_vec(neg_ids)\n",
    "\n",
    "\n",
    "            # 归一化（与 forward 保持一致）\n",
    "            u_vec = F.normalize(u_vec, p=2, dim=1)\n",
    "            pos_vec = F.normalize(pos_vec, p=2, dim=1)\n",
    "            neg_vec = F.normalize(neg_vec, p=2, dim=1)\n",
    "\n",
    "            loss = bpr_loss((u_vec * pos_vec).sum(-1), (u_vec * neg_vec).sum(-1))\n",
    "\n",
    "            # 5.反向 & 更新\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if max_grad_norm is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # —— epoch 结束，打印日志 ——\n",
    "        avg_loss = epoch_loss / num_steps\n",
    "        if epoch % print_every == 0:\n",
    "            print(f\"[Epoch {epoch:02d}/{epochs}]  avg BPR Loss = {avg_loss:.4f}\")\n",
    "\n",
    "    return\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "10c90823",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:47.502968Z",
     "start_time": "2025-06-30T17:31:47.492463Z"
    }
   },
   "source": [
    "\n",
    "def evaluate_ranking(\n",
    "        test_df,              # DataFrame, 必含 user_id / item_id\n",
    "        train_df,             # DataFrame, 用来构建用户→已交互物品集合\n",
    "        score_fn,             # callable(users_tensor, items_tensor) → np.array\n",
    "        num_items,            # 物品总数\n",
    "        k=10,                 # Hit@K / NDCG@K\n",
    "        num_neg=100,          # 每个正样本采多少负样本\n",
    "        user_col='user_id',\n",
    "        item_col='item_id',\n",
    "        seed=42\n",
    "    ):\n",
    "    \"\"\"\n",
    "    不依赖具体模型，只要提供 score_fn 就能评估。\n",
    "    score_fn: 接收 (user_tensor, item_tensor) 并返回同长度的 Numpy 分数向量。\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # 用户历史，用于采负样本 & 过滤\n",
    "    train_user_dict = (\n",
    "        train_df.groupby(user_col)[item_col].apply(set).to_dict()\n",
    "    )\n",
    "\n",
    "    hits, ndcgs = [], []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        u = int(row[user_col])\n",
    "        pos_item = int(row[item_col])\n",
    "\n",
    "        # ---------- 负采样 ----------\n",
    "        neg_items = set()\n",
    "        while len(neg_items) < num_neg:\n",
    "            neg = random.randint(0, num_items - 1)\n",
    "            if neg not in train_user_dict.get(u, set()) and neg != pos_item:\n",
    "                neg_items.add(neg)\n",
    "\n",
    "        item_candidates = list(neg_items) + [pos_item]\n",
    "\n",
    "        # ---------- 评分 ----------\n",
    "        users_t  = torch.LongTensor([u] * len(item_candidates))\n",
    "        items_t  = torch.LongTensor(item_candidates)\n",
    "        scores   = score_fn(users_t, items_t)        # ← 只依赖 score_fn\n",
    "        rank_idx = np.argsort(scores)[::-1]          # 降序\n",
    "        ranked_items = [item_candidates[i] for i in rank_idx]\n",
    "\n",
    "        # ---------- 指标 ----------\n",
    "        if pos_item in ranked_items[:k]:\n",
    "            hits.append(1)\n",
    "            rank_pos = ranked_items.index(pos_item)\n",
    "            ndcgs.append(1 / np.log2(rank_pos + 2))\n",
    "        else:\n",
    "            hits.append(0)\n",
    "            ndcgs.append(0)\n",
    "\n",
    "    hit_rate = float(np.mean(hits))\n",
    "    ndcg     = float(np.mean(ndcgs))\n",
    "    return hit_rate, ndcg"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b28f36ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:47.540602Z",
     "start_time": "2025-06-30T17:31:47.534167Z"
    }
   },
   "source": [
    "# Top-K recommendation for a user\n",
    "def recommend_top_k(model, user_id, train_df, k=10):\n",
    "    model.eval()\n",
    "    user_emb, item_emb = model.get_embedding()\n",
    "    seen_items = set(train_df[train_df['user_id'] == user_id]['item_id'])\n",
    "    all_items = torch.arange(model.num_items)\n",
    "    scores = model.predict(torch.LongTensor([user_id] * model.num_items), all_items).detach().numpy()\n",
    "\n",
    "    ranked_items = np.argsort(scores)[::-1]\n",
    "    recommended = [i for i in ranked_items if i not in seen_items][:k]\n",
    "    return recommended"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "72feadb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:31:47.579212Z",
     "start_time": "2025-06-30T17:31:47.573199Z"
    }
   },
   "source": [
    "# Save and load model\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "2502c98c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:34:15.095849Z",
     "start_time": "2025-06-30T17:31:47.611341Z"
    }
   },
   "source": [
    "\n",
    "# ----- Instantiate DSSM with cover embeddings -----\n",
    "model = DSSM(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    id_emb_dim=64,            # keep same ID embedding dim as before\n",
    "    cover_matrix=cover_matrix,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "train_model(model=model, epochs=30, train_df=train_df, num_items=num_items)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 01/30]  avg BPR Loss = 0.6109\n",
      "[Epoch 02/30]  avg BPR Loss = 0.5879\n",
      "[Epoch 03/30]  avg BPR Loss = 0.5839\n",
      "[Epoch 04/30]  avg BPR Loss = 0.5801\n",
      "[Epoch 05/30]  avg BPR Loss = 0.5762\n",
      "[Epoch 06/30]  avg BPR Loss = 0.5702\n",
      "[Epoch 07/30]  avg BPR Loss = 0.5667\n",
      "[Epoch 08/30]  avg BPR Loss = 0.5639\n",
      "[Epoch 09/30]  avg BPR Loss = 0.5622\n",
      "[Epoch 10/30]  avg BPR Loss = 0.5597\n",
      "[Epoch 11/30]  avg BPR Loss = 0.5597\n",
      "[Epoch 12/30]  avg BPR Loss = 0.5582\n",
      "[Epoch 13/30]  avg BPR Loss = 0.5573\n",
      "[Epoch 14/30]  avg BPR Loss = 0.5574\n",
      "[Epoch 15/30]  avg BPR Loss = 0.5565\n",
      "[Epoch 16/30]  avg BPR Loss = 0.5559\n",
      "[Epoch 17/30]  avg BPR Loss = 0.5562\n",
      "[Epoch 18/30]  avg BPR Loss = 0.5557\n",
      "[Epoch 19/30]  avg BPR Loss = 0.5563\n",
      "[Epoch 20/30]  avg BPR Loss = 0.5554\n",
      "[Epoch 21/30]  avg BPR Loss = 0.5546\n",
      "[Epoch 22/30]  avg BPR Loss = 0.5546\n",
      "[Epoch 23/30]  avg BPR Loss = 0.5538\n",
      "[Epoch 24/30]  avg BPR Loss = 0.5539\n",
      "[Epoch 25/30]  avg BPR Loss = 0.5546\n",
      "[Epoch 26/30]  avg BPR Loss = 0.5543\n",
      "[Epoch 27/30]  avg BPR Loss = 0.5542\n",
      "[Epoch 28/30]  avg BPR Loss = 0.5540\n",
      "[Epoch 29/30]  avg BPR Loss = 0.5539\n",
      "[Epoch 30/30]  avg BPR Loss = 0.5532\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "900b523c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:34:15.167230Z",
     "start_time": "2025-06-30T17:34:15.160192Z"
    }
   },
   "source": [
    "def make_popularity_score_fn(train_df, item_col='item_id'):\n",
    "    item_cnt = Counter(train_df[item_col])\n",
    "    default_score = min(item_cnt.values()) - 1  # 给没出现过的物品一个更低分\n",
    "    def _score_fn(users_t, items_t):\n",
    "        return np.array([item_cnt.get(int(i), default_score) for i in items_t])\n",
    "    return _score_fn"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "994e2156",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:34:15.183244Z",
     "start_time": "2025-06-30T17:34:15.177778Z"
    }
   },
   "source": [
    "def random_score_fn(users_t, items_t):\n",
    "    # 随机给每个 items_t 一个分数；users_t 不使用，但必须接收\n",
    "    return np.random.rand(len(items_t))"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "4ef6ceb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:34:15.222488Z",
     "start_time": "2025-06-30T17:34:15.216335Z"
    }
   },
   "source": [
    "def make_DSSM_score_fn(model):\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     score = model.get_embedding(users_t,items_t)\n",
    "    #     user_emb = user_emb.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #     item_emb = item_emb.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def score_fn(users_t, items_t):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "         users_t = users_t.to(device)\n",
    "         items_t = items_t.to(device)\n",
    "         scores = model.get_embedding(users_t,items_t)\n",
    "         return scores.cpu().detach().numpy()\n",
    "        # u_vec = user_emb[users_t]\n",
    "        # i_vec = item_emb[items_t]\n",
    "        # return torch.sum(u_vec * i_vec, dim=1).detach().cpu().numpy()\n",
    "    return score_fn"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "bbd4f9d7af8b5c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T17:36:55.132750Z",
     "start_time": "2025-06-30T17:34:15.254833Z"
    }
   },
   "source": [
    "\n",
    "# ---------------- DSSM（或其他模型）------------\n",
    "score_fn_dssm = make_DSSM_score_fn(model)\n",
    "hit_dssm, ndcg_dssm = evaluate_ranking(\n",
    "    test_df, train_df, score_fn_dssm,\n",
    "    num_items=num_items, k=10\n",
    ")\n",
    "print(f\"DSSM   Hit@10={hit_dssm:.4f}  NDCG@10={ndcg_dssm:.4f}\")\n",
    "\n",
    "# ---------------- baseline：Popular ----------------\n",
    "pop_score_fn  = make_popularity_score_fn(train_df)\n",
    "hit_pop, ndcg_pop = evaluate_ranking(\n",
    "    test_df, train_df, pop_score_fn,\n",
    "    num_items=num_items, k=10\n",
    ")\n",
    "print(f\"Popular  Hit@10={hit_pop:.4f}  NDCG@10={ndcg_pop:.4f}\")\n",
    "\n",
    "# ---------------- baseline：Random -----------------\n",
    "hit_rand, ndcg_rand = evaluate_ranking(\n",
    "    test_df, train_df, random_score_fn,\n",
    "    num_items=num_items, k=10\n",
    ")\n",
    "print(f\"Random   Hit@10={hit_rand:.4f}  NDCG@10={ndcg_rand:.4f}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSSM   Hit@10=0.2697  NDCG@10=0.1236\n",
      "Popular  Hit@10=0.2528  NDCG@10=0.1262\n",
      "Random   Hit@10=0.0996  NDCG@10=0.0455\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DP1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
