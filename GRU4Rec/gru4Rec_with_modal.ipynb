{
  "cells": [
    {
      "metadata": {
        "id": "365b909de4764032",
        "outputId": "b3e6571d-2ab2-4e50-c2de-1535bcfddea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "ExecuteTime": {
          "end_time": "2025-08-04T17:35:07.765327Z",
          "start_time": "2025-08-04T17:35:06.436748Z"
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "def copy_from_drive(src_path, dst_path):\n",
        "\n",
        "    if os.path.exists(dst_path):\n",
        "        print(f\"skip:{dst_path} exists\")\n",
        "        return\n",
        "\n",
        "    if os.path.isdir(src_path):\n",
        "        shutil.copytree(src_path, dst_path)\n",
        "    elif os.path.isfile(src_path):\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "copy_from_drive('/content/drive/MyDrive/tool', '/content/tool')\n",
        "copy_from_drive('/content/drive/MyDrive/MicroLens-50k_pairs.csv','/content/MicroLens-50k_pairs.csv')\n",
        "copy_from_drive('/content/drive/MyDrive/cover_emb128.lmdb','/content/cover_emb128.lmdb')\n",
        "copy_from_drive('/content/drive/MyDrive/title_emb1024.lmdb','/content/title_emb1024.lmdb')\n"
      ],
      "id": "365b909de4764032",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "skip:/content/tool exists\n",
            "skip:/content/MicroLens-50k_pairs.csv exists\n",
            "skip:/content/cover_emb128.lmdb exists\n",
            "skip:/content/title_emb1024.lmdb exists\n"
          ]
        }
      ],
      "execution_count": 155
    },
    {
      "cell_type": "code",
      "id": "b828e981",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:33.313152Z",
          "start_time": "2025-06-07T12:50:24.994875Z"
        },
        "id": "b828e981",
        "outputId": "4421a794-8f75-4845-9dfd-6b0785785a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install lmdb\n",
        "from tool import preprocess\n",
        "from tool import customdataset\n",
        "from tool import evaluate\n",
        "import faiss\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from datetime import datetime\n",
        "import math\n",
        "import csv\n",
        "from matplotlib import pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.12/dist-packages (1.7.5)\n"
          ]
        }
      ],
      "execution_count": 156
    },
    {
      "metadata": {
        "id": "78f0ef2440dcdd21",
        "outputId": "d4f2013a-19b3-4440-cf30-efe9eb4456a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tool.preprocess.set_seed.<locals>.seed_worker(worker_id)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tool.preprocess.set_seed.&lt;locals&gt;.seed_worker</b><br/>def seed_worker(worker_id)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/tool/preprocess.py</a>&lt;no docstring&gt;</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 18);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "execution_count": 157,
      "source": [
        "preprocess.set_seed(42)"
      ],
      "id": "78f0ef2440dcdd21"
    },
    {
      "cell_type": "code",
      "id": "e99a31348e0a553",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:33.369715Z",
          "start_time": "2025-06-07T12:50:33.324174Z"
        },
        "id": "e99a31348e0a553"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "outputs": [],
      "execution_count": 158
    },
    {
      "metadata": {
        "id": "2c5867a25e9d58a0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 159,
      "source": [
        "path = 'MicroLens-50k_pairs.csv'\n",
        "user = 'user'\n",
        "item = 'item'\n",
        "user_id = 'user_id'\n",
        "item_id = 'item_id'\n",
        "timestamp = 'timestamp'\n",
        "save_dir = './embeddings'\n",
        "cover_lmdb_path = 'cover_emb128.lmdb'\n",
        "title_lmdb_path = 'title_emb1024.lmdb'\n",
        "record_path = './records'\n",
        "TOP_K= 10\n",
        "NUM_WORKERS = 10\n",
        "PATIENCE = 5\n",
        "MONITOR = 'hr'"
      ],
      "id": "2c5867a25e9d58a0"
    },
    {
      "cell_type": "code",
      "id": "943fc6c5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:34.217714Z",
          "start_time": "2025-06-07T12:50:34.201507Z"
        },
        "id": "943fc6c5",
        "outputId": "f5b93a08-dd54-479f-82dc-3e7e48a49263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_pd,num_users,num_items = preprocess.openAndSort(path,user_id=user,item_id=item,timestamp='timestamp')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset base information：\n",
            "- number of users：50000\n",
            "- number of items：19220\n",
            "- number of rows：359708\n"
          ]
        }
      ],
      "execution_count": 160
    },
    {
      "metadata": {
        "id": "3f9c39281871293a"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 161,
      "source": [
        "# ---------- 超参数 ----------\n",
        "MAX_SEQ_LEN   = 20          # 输入序列长度\n",
        "EMBEDDING_DIM = 64          # item / user embedding 维度\n",
        "HIDDEN_SIZE   = 64          # GRU 隐藏维度（可与 EMBEDDING_DIM 相同）\n",
        "BATCH_SIZE    = 1024\n",
        "EPOCHS        = 60\n",
        "LR            = 1e-3\n",
        "SEED          = 42\n",
        "NUM_LAYERS      = 1\n",
        "MODAL = {'COVER':{\"LMDB_DIM\":128, \"HIDDEN_SIZE\":[EMBEDDING_DIM],\"DROPOUT\":0.2} , 'TITLE':{\"LMDB_DIM\":1024,\"HIDDEN_SIZE\":[EMBEDDING_DIM],\"DROPOUT\":0.2}\n",
        "         ,'COVER-TITLE': {\"LMDB_DIM\":128+1024, \"HIDDEN_SIZE\":[EMBEDDING_DIM],\"DROPOUT\":0.2}}\n",
        "FUSION_MODE = \"late2\"\n",
        "CURRENT_MODAL = \"COVER-TITLE\"\n",
        "MODAL_CONFIG = MODAL[CURRENT_MODAL]\n",
        "MODAL_HIDDEN_SIZE = MODAL_CONFIG.get('HIDDEN_SIZE')\n",
        "LMDB_DIM = MODAL_CONFIG.get('LMDB_DIM')\n",
        "MODAL_DROPOUT = MODAL_CONFIG.get('DROPOUT')\n",
        "L2_NORM =False\n",
        "PROJECT_NAME = \"GRU4Rec\"\n",
        "# ----------------------------\n",
        "\n",
        "# ---------- 随机种子 ----------\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "# ----------------------------\n",
        "\n",
        "# ---------- 常量 ----------\n",
        "PAD_IDX  = num_items              # padding 专用 id（不与真实 item 冲突）\n",
        "N_ITEMS  = num_items + 1          # Embedding 行数（含 PAD）\n",
        "# ----------------------------\n",
        "\n"
      ],
      "id": "3f9c39281871293a"
    },
    {
      "cell_type": "code",
      "id": "6d42c375",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:34.448028Z",
          "start_time": "2025-06-07T12:50:34.415887Z"
        },
        "id": "6d42c375",
        "outputId": "3098355c-99dd-4e0e-dd85-3b34ad18656f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df, val_df, test_df, train_all_df = preprocess.split_with_val(dataset_pd,user, item, timestamp)\n",
        "print(f\"Train size: {len(train_df)}\")\n",
        "print(f\"Val_df size: {len(val_df)}\")\n",
        "print(f\"Test_df size: {len(test_df)}\")\n",
        "print(f\"Train_all_df size: {len(train_all_df)}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 259708\n",
            "Val_df size: 49156\n",
            "Test_df size: 47774\n",
            "Train_all_df size: 308864\n"
          ]
        }
      ],
      "execution_count": 162
    },
    {
      "cell_type": "code",
      "id": "8b8ae0c7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:34.672397Z",
          "start_time": "2025-06-07T12:50:34.523061Z"
        },
        "id": "8b8ae0c7"
      },
      "source": [
        "# maintain a map from new id to old id, new id for constructing matrix\n",
        "user2id = {u: i for i, u in enumerate(dataset_pd[user].unique())}\n",
        "item2id = {i: j for j, i in enumerate(dataset_pd[item].unique())}\n",
        "\n",
        "# apply to train_df and test_df\n",
        "train_df[user_id] = train_df[user].map(user2id)\n",
        "train_df[item_id] = train_df[item].map(item2id)\n",
        "val_df[user_id] = val_df[user].map(user2id)\n",
        "val_df[item_id] = val_df[item].map(item2id)\n",
        "test_df[user_id] = test_df[user].map(user2id)\n",
        "test_df[item_id] = test_df[item].map(item2id)\n",
        "train_all_df[user_id] = train_all_df[user].map(user2id)\n",
        "train_all_df[item_id] = train_all_df[item].map(item2id)\n",
        "\n",
        "# 1. 构建 item_id 到 item 的映射（来自 train_df）\n",
        "item_id_to_item = {v: k for k, v in item2id.items()}"
      ],
      "outputs": [],
      "execution_count": 163
    },
    {
      "cell_type": "code",
      "id": "a7aba75c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:36.269499Z",
          "start_time": "2025-06-07T12:50:36.261103Z"
        },
        "id": "a7aba75c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class GRU4Rec(nn.Module):\n",
        "    def __init__(self, n_items=N_ITEMS,\n",
        "                 embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE,\n",
        "                 modal_hidden_size=MODAL_HIDDEN_SIZE, modal_dropout=MODAL_DROPOUT, lmdb_dim=LMDB_DIM,\n",
        "                 num_layers=NUM_LAYERS, pad_idx=PAD_IDX,\n",
        "                 fusion_mode=FUSION_MODE):  # 'base' | 'early' | 'late1' | 'late2'\n",
        "        super().__init__()\n",
        "        assert fusion_mode in {'base', 'early', 'late1' , 'late2'}\n",
        "        self.fusion_mode = fusion_mode\n",
        "\n",
        "        # ---------- Item embedding (ID) ----------\n",
        "        self.embedding = nn.Embedding(n_items, embedding_dim, padding_idx=pad_idx)\n",
        "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.05)\n",
        "        with torch.no_grad():\n",
        "            self.embedding.weight[self.embedding.padding_idx].zero_()  # PAD → 0\n",
        "\n",
        "        # ---------- User encoder ----------\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.proj = (nn.Linear(hidden_size, embedding_dim, bias=False)\n",
        "                     if hidden_size != embedding_dim else nn.Identity())\n",
        "\n",
        "        # modal 向量（冻结）\n",
        "        modal_emb_tensor = None\n",
        "        if FUSION_MODE!='base':\n",
        "            if CURRENT_MODAL=='COVER':\n",
        "                modal_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
        "                    cover_lmdb_path, num_items, item_id_to_item, lmdb_dim\n",
        "                )\n",
        "            if CURRENT_MODAL=='TITLE':\n",
        "                modal_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
        "                    title_lmdb_path, num_items, item_id_to_item, lmdb_dim\n",
        "                )\n",
        "            if CURRENT_MODAL=='COVER-TITLE':\n",
        "                cover_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
        "                    cover_lmdb_path, num_items, item_id_to_item, 128\n",
        "                )\n",
        "                title_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
        "                    title_lmdb_path, num_items, item_id_to_item, 1024\n",
        "                )\n",
        "                modal_emb_tensor = torch.cat([cover_emb_tensor, title_emb_tensor], dim=-1)\n",
        "            pad_vec = torch.zeros(1, lmdb_dim)\n",
        "            modal_emb_tensor = torch.cat([modal_emb_tensor, pad_vec], dim=0)\n",
        "            self.register_buffer('frozen_extra_emb', modal_emb_tensor)\n",
        "\n",
        "\n",
        "        # ---------- 前融合用的投影：[id_emb; modal] -> emb_dim ----------\n",
        "        self.mlp_item_modal = self.build_mlp(embedding_dim + lmdb_dim, modal_hidden_size, modal_dropout)\n",
        "\n",
        "        # ---------- 后融合用 α（全局标量） ----------\n",
        "        # sigmoid(0)=0.5，起步两路各占一半；如需更稳可设为 1.0（偏向 ID）\n",
        "        # 用户侧 β（让 late 对称）\n",
        "        self.alpha_param = nn.Parameter(torch.tensor(0.0)) if fusion_mode == 'late1' or fusion_mode == 'late2' else None\n",
        "        self.beta_param  = nn.Parameter(torch.tensor(0.0)) if fusion_mode == 'late2' else None\n",
        "\n",
        "    def build_mlp(self, input_dim, hidden_sizes, dropout):\n",
        "        layers = []\n",
        "        for h in hidden_sizes:\n",
        "            layers += [nn.Linear(input_dim, h), nn.LayerNorm(h), nn.Tanh(), nn.Dropout(dropout)]\n",
        "            input_dim = h\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    # ===================== 用户侧（序列） =====================\n",
        "    def _seq_emb_id_only(self, seq):\n",
        "        \"\"\"仅用 ID embedding 作为 GRU 输入\"\"\"\n",
        "        return self.embedding(seq)  # (B,T,D)\n",
        "\n",
        "    def _seq_emb_early(self, seq):\n",
        "        \"\"\"前融合：在时间步拼接 modal 再映射回 emb_dim\"\"\"\n",
        "        modal = self.frozen_extra_emb.to(seq.device)[seq]          # (B,T,lmdb_dim)\n",
        "        emb   = self.embedding(seq)                                 # (B,T,D)\n",
        "        emb   = torch.cat([emb, modal], dim=-1)                     # (B,T,D+lmdb_dim)\n",
        "        emb   = self.mlp_item_modal(emb)                            # (B,T,D)\n",
        "        return emb\n",
        "\n",
        "    def _encode_user_from_seq_emb(self, emb_seq):\n",
        "        out, _ = self.gru(emb_seq)      # (B,T,H)\n",
        "        h = out[:, -1, :]               # (B,H)\n",
        "        u = self.proj(h)                # (B,D)\n",
        "        return u\n",
        "\n",
        "    def forward(self, seq):\n",
        "        \"\"\"\n",
        "        输入:  seq (B,T)\n",
        "        输出:  用户向量 u_vec (B,D)\n",
        "        说明:  只负责用户向量；物品向量交给 get_items_embedding 按 fusion_mode 产出\n",
        "        \"\"\"\n",
        "        if self.fusion_mode == 'early':\n",
        "            emb = self._seq_emb_early(seq)\n",
        "            out, _ = self.gru(emb)             # (B,T,H)\n",
        "            h = out[:, -1, :]                  # (B,H)\n",
        "            u_vec = self.proj(h)               # (B,D)\n",
        "        elif self.fusion_mode == 'base':\n",
        "            # 'base' 与 'late' 都建议用 ID-only 序列来编码用户状态（最小侵入、计算稳定）\n",
        "            emb = self._seq_emb_id_only(seq)\n",
        "            out, _ = self.gru(emb)             # (B,T,H)\n",
        "            h = out[:, -1, :]                  # (B,H)\n",
        "            u_vec = self.proj(h)               # (B,D)\n",
        "        elif self.fusion_mode == 'late1':\n",
        "            # 'base' 与 'late1' 都建议用 ID-only 序列来编码用户状态（最小侵入、计算稳定）\n",
        "            emb = self._seq_emb_id_only(seq)\n",
        "            out, _ = self.gru(emb)             # (B,T,H)\n",
        "            h = out[:, -1, :]                  # (B,H)\n",
        "            u_vec = self.proj(h)               # (B,D)\n",
        "        else:\n",
        "            # 'late2'：对称地融合用户侧（β）\n",
        "            u_id = self._encode_user_from_seq_emb(self._seq_emb_id_only(seq))\n",
        "            u_mm = self._encode_user_from_seq_emb(self._seq_emb_early(seq))\n",
        "            beta = torch.sigmoid(self.beta_param)\n",
        "            u_vec = beta * u_id + (1.0 - beta) * u_mm\n",
        "\n",
        "\n",
        "\n",
        "        if L2_NORM:\n",
        "            u_vec = F.normalize(u_vec, p=2, dim=1)\n",
        "        return u_vec\n",
        "\n",
        "    # ===================== 物品侧（候选向量） =====================\n",
        "    def _item_vec_id_only(self, item_ids, l2_norm=False):\n",
        "        i_vec = self.embedding(item_ids)   # (B,D)\n",
        "        if l2_norm:\n",
        "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
        "        return i_vec\n",
        "\n",
        "    def _item_vec_early(self, item_ids, l2_norm=False):\n",
        "        modal = self.frozen_extra_emb.to(item_ids.device)[item_ids]  # (B,lmdb_dim)\n",
        "        i_vec = self.embedding(item_ids)                              # (B,D)\n",
        "        i_vec = torch.cat([i_vec, modal], dim=-1)                     # (B,D+lmdb_dim)\n",
        "        i_vec = self.mlp_item_modal(i_vec)                            # (B,D)\n",
        "        if l2_norm:\n",
        "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
        "        return i_vec\n",
        "\n",
        "    def _item_vec_late(self, item_ids, l2_norm=False):\n",
        "        # 向量级后融合：i = α * i_id + (1-α) * i_mm\n",
        "        i_id = self._item_vec_id_only(item_ids, l2_norm=False)   # (B,D)\n",
        "        i_mm = self._item_vec_early(item_ids, l2_norm=False)     # (B,D)\n",
        "        alpha = torch.sigmoid(self.alpha_param)                  # 标量\n",
        "        i_vec = alpha * i_id + (1.0 - alpha) * i_mm\n",
        "        if l2_norm:\n",
        "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
        "        return i_vec\n",
        "\n",
        "    def get_items_embedding(self, item_ids, l2_norm=False):\n",
        "        \"\"\"\n",
        "        根据 fusion_mode 返回候选物品向量（用于打分/ANN 检索）\n",
        "        \"\"\"\n",
        "        if self.fusion_mode == 'base':\n",
        "            return self._item_vec_id_only(item_ids, l2_norm=l2_norm)\n",
        "        elif self.fusion_mode == 'early':\n",
        "            return self._item_vec_early(item_ids, l2_norm=l2_norm)\n",
        "        else:  # 'late'\n",
        "            return self._item_vec_late(item_ids, l2_norm=l2_norm)\n",
        "\n",
        "    # ===================== 导出/检索 =====================\n",
        "    def save_embeddings(self, num_users, num_items, device, save_dir='./embeddings', l2_norm=L2_NORM):\n",
        "        import os, faiss\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        self.eval().to(device)\n",
        "\n",
        "        item_ids = torch.arange(num_items, dtype=torch.long, device=device)\n",
        "        with torch.no_grad():\n",
        "            item_embeds = self.get_items_embedding(item_ids, l2_norm=l2_norm)\n",
        "\n",
        "        item_embeds = item_embeds.cpu().numpy().astype(np.float32)\n",
        "        np.save(f\"{save_dir}/item_embeddings.npy\", item_embeds)\n",
        "\n",
        "        dim = item_embeds.shape[1]\n",
        "        index = faiss.IndexFlatIP(dim)\n",
        "        index.add(item_embeds)\n",
        "        faiss.write_index(index, f\"{save_dir}/item_index.faiss\")\n",
        "        print(\"Saved item embeddings and FAISS index.\")\n"
      ],
      "outputs": [],
      "execution_count": 164
    },
    {
      "cell_type": "code",
      "id": "07e268c2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:36.330578Z",
          "start_time": "2025-06-07T12:50:36.319538Z"
        },
        "id": "07e268c2"
      },
      "source": [
        "# ======== 训练流程 ======== #\n",
        "def train_model(model,\n",
        "                train_df,\n",
        "                val_df,\n",
        "                top_k,\n",
        "                epochs,\n",
        "                lr ,\n",
        "                val_mode,\n",
        "                batch_size ,\n",
        "                device=None,\n",
        "                patience=PATIENCE, # 早停容忍\n",
        "                monitor=MONITOR,       # \"hr\" 或 \"ndcg\"\n",
        "                record_path = record_path):\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "    train_loader  = customdataset.build_seq_loader(train_df, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=10,pad_idx=PAD_IDX,max_len=MAX_SEQ_LEN,user_id=user_id,item_id=item_id)\n",
        "    val_loader = customdataset.build_test_loader(val_df, num_items ,user_col = user_id, item_col = item_id, batch_size=1024, num_workers=NUM_WORKERS)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # 训练过程记录\n",
        "    history = {\n",
        "        \"epoch\": [],\n",
        "        \"loss\": [],\n",
        "        f\"hr@{top_k}\": [],\n",
        "        f\"ndcg@{top_k}\": [],\n",
        "        \"alpha\": [],\n",
        "        \"beta\": [],\n",
        "    }\n",
        "\n",
        "    # 早停配置\n",
        "    best_metric = -math.inf\n",
        "    best_epoch  = -1\n",
        "    patience_cnt = 0\n",
        "    monitor_key = f\"{monitor}@{top_k}\"\n",
        "\n",
        "    print(f\"[EarlyStopping] monitor={monitor_key} , patience={patience}\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        dt_start = datetime.now()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            hist, pos = batch\n",
        "            hist, pos = hist.to(device), pos.to(device)\n",
        "\n",
        "            # 1. 前向传播（返回预测向量）\n",
        "            predict = model(hist)                      # (B, D)\n",
        "            i_vec = model.get_items_embedding(pos,l2_norm=False)\n",
        "\n",
        "            # 2. 得分矩阵：每个 user 对所有正 item 的打分\n",
        "            logits = torch.matmul(predict, i_vec.T)  # shape: (B, B)\n",
        "\n",
        "            # 3. 构造标签：每个 user 的正确 item 在对角线（即位置 i）\n",
        "            labels = torch.arange(logits.size(0), device=device)  # [0, 1, ..., B-1]\n",
        "\n",
        "            # 4. Cross Entropy Loss\n",
        "            loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "            # 5. 反向传播\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # 日志\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        dt_end = datetime.now()\n",
        "        dt = (dt_end - dt_start).total_seconds()\n",
        "\n",
        "        model.save_embeddings(num_users=num_users,num_items=num_items,device=device,save_dir=save_dir)\n",
        "        faiss_index = faiss.read_index(f\"{save_dir}/item_index.faiss\")\n",
        "        model.eval()\n",
        "        hr_m, ndcg_m = evaluate.evaluate_seq_model(val_loader, model, faiss_index, device, top_k=top_k,hist_tensors=hist_tensors)\n",
        "\n",
        "        # gates（若存在）\n",
        "        alpha_val = float(torch.sigmoid(model.alpha_param).item()) if hasattr(model, \"alpha_param\") and model.alpha_param is not None else float(\"nan\")\n",
        "        beta_val  = float(torch.sigmoid(model.beta_param).item())  if hasattr(model, \"beta_param\") and model.beta_param is not None else float(\"nan\")\n",
        "\n",
        "        print(f\"[Epoch {epoch:02d}/{epochs}] avg InBatch Softmax Loss = {avg_loss:.4f}, \"\n",
        "              f\"HR@{top_k} = {hr_m:.4f}, NDCG@{top_k} = {ndcg_m:.4f}, \"\n",
        "              f\"alpha={alpha_val if not math.isnan(alpha_val) else 'NA'}, \"\n",
        "              f\"beta={beta_val if not math.isnan(beta_val) else 'NA'}, \"\n",
        "              f\"time = {dt:.2f}s\")\n",
        "\n",
        "        # —— 记录历史 ——\n",
        "        history[\"epoch\"].append(epoch)\n",
        "        history[\"loss\"].append(avg_loss)\n",
        "        history[f\"hr@{top_k}\"].append(hr_m)\n",
        "        history[f\"ndcg@{top_k}\"].append(ndcg_m)\n",
        "        history[\"alpha\"].append(alpha_val)\n",
        "        history[\"beta\"].append(beta_val)\n",
        "\n",
        "        # —— 早停判断（最大化 monitor 指标）——\n",
        "        if val_mode:\n",
        "          current_metric = hr_m if monitor == \"hr\" else ndcg_m\n",
        "          if current_metric > best_metric:\n",
        "              best_metric = current_metric\n",
        "              best_epoch = epoch\n",
        "              patience_cnt = 0\n",
        "              print(f\"current best {monitor_key}={best_metric:.4f} @ epoch {epoch}.\")\n",
        "                          # ==== 保存最佳 hr / ndcg / epoch ====\n",
        "              best_info_path = os.path.join(record_path,\n",
        "                                            \"validation mode\" if val_mode else \"train mode\",\n",
        "                                            \"best_result.txt\")\n",
        "              os.makedirs(os.path.dirname(best_info_path), exist_ok=True)\n",
        "              with open(best_info_path, \"w\") as f:\n",
        "                  f.write(f\"epoch: {epoch}\\n\")\n",
        "                  f.write(f\"HR@{top_k}: {hr_m:.4f}\\n\")\n",
        "                  f.write(f\"NDCG@{top_k}: {ndcg_m:.4f}\\n\")\n",
        "              print(f\"Best result info saved to {best_info_path}\")\n",
        "          else:\n",
        "              patience_cnt += 1\n",
        "              if patience_cnt >= patience:\n",
        "                  print(\"Early stopping triggered.\")\n",
        "                  break\n",
        "\n",
        "    # —— 导出历史 CSV ——\n",
        "    csv_path = os.path.join(record_path,\"validation mode\" if val_mode else \"train mode\",\"training_history.csv\")\n",
        "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)  # 确保目录存在\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"epoch\", \"loss\", f\"hr@{top_k}\", f\"ndcg@{top_k}\", \"alpha\", \"beta\", \"time_sec\"])\n",
        "        for i in range(len(history[\"epoch\"])):\n",
        "            writer.writerow([\n",
        "                history[\"epoch\"][i],\n",
        "                history[\"loss\"][i],\n",
        "                history[f\"hr@{top_k}\"][i],\n",
        "                history[f\"ndcg@{top_k}\"][i],\n",
        "                history[\"alpha\"][i],\n",
        "                history[\"beta\"][i],\n",
        "            ])\n",
        "    # —— 绘图：Loss ——\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(history[\"epoch\"], history[\"loss\"])\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"In-Batch CE Loss\"); plt.title(\"Training Loss\")\n",
        "    plt.grid(True, linestyle=\"--\", alpha=0.4); plt.tight_layout()\n",
        "    plt.xticks(range(1, max(history[\"epoch\"]) + 1, 1))\n",
        "    fig1_path = os.path.join(record_path,\"validation mode\" if val_mode else \"train mode\",\"curve_loss.png\")\n",
        "    os.makedirs(os.path.dirname(fig1_path), exist_ok=True)  # 确保目录存在\n",
        "\n",
        "    plt.savefig(fig1_path, dpi=150); plt.close()\n",
        "    print(f\"Saved {fig1_path}\")\n",
        "\n",
        "    # —— 绘图：HR/NDCG ——\n",
        "    plt.figure()\n",
        "    plt.plot(history[\"epoch\"], history[f\"hr@{top_k}\"], label=f\"HR@{top_k}\")\n",
        "    plt.plot(history[\"epoch\"], history[f\"ndcg@{top_k}\"], label=f\"NDCG@{top_k}\")\n",
        "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Metric\"); plt.title(\"Validation Metrics\")\n",
        "    plt.legend(); plt.grid(True, linestyle=\"--\", alpha=0.4); plt.tight_layout()\n",
        "    plt.xticks(range(1, max(history[\"epoch\"]) + 1, 1))\n",
        "    fig2_path = os.path.join(record_path,\"validation mode\" if val_mode else \"train mode\",\"curve_metrics.png\")\n",
        "    os.makedirs(os.path.dirname(fig2_path), exist_ok=True)  # 确保目录存在\n",
        "    plt.savefig(fig2_path, dpi=150); plt.close()\n",
        "    print(f\"Saved {fig2_path}\")\n",
        "\n",
        "    # —— 绘图：alpha/beta（如存在） ——\n",
        "    if not all(math.isnan(v) for v in history[\"alpha\"]) or not all(math.isnan(v) for v in history[\"beta\"]):\n",
        "        plt.figure()\n",
        "        if not all(math.isnan(v) for v in history[\"alpha\"]):\n",
        "            plt.plot(history[\"epoch\"], history[\"alpha\"], label=\"alpha (item late)\")\n",
        "        if not all(math.isnan(v) for v in history[\"beta\"]):\n",
        "            plt.plot(history[\"epoch\"], history[\"beta\"],  label=\"beta (user late)\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Gate (sigmoid)\"); plt.title(\"Late Fusion Gates\")\n",
        "        plt.ylim(0, 1); plt.legend(); plt.grid(True, linestyle=\"--\", alpha=0.4); plt.tight_layout()\n",
        "        plt.xticks(range(1, max(history[\"epoch\"]) + 1, 1))\n",
        "        fig3_path = os.path.join(record_path,\"validation mode\" if val_mode else \"train mode\",\"curve_alpha_beta.png\")\n",
        "        os.makedirs(os.path.dirname(fig3_path), exist_ok=True)  # 确保目录存在\n",
        "        plt.savefig(fig3_path, dpi=150); plt.close()\n",
        "        print(f\"Saved {fig3_path}\")\n",
        "\n",
        "    print(f\"Best {monitor_key}={best_metric:.4f} at epoch {best_epoch}\")\n",
        "    return best_epoch"
      ],
      "outputs": [],
      "execution_count": 165
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T12:50:36.371982Z",
          "start_time": "2025-06-07T12:50:36.365209Z"
        },
        "id": "9bc49db2aee62849"
      },
      "cell_type": "code",
      "source": [
        "def build_hist_matrix(df,\n",
        "                      num_users,\n",
        "                      max_len=MAX_SEQ_LEN,\n",
        "                      pad_idx=PAD_IDX,\n",
        "                      user_col=user_id,\n",
        "                      item_col=item_id):\n",
        "    \"\"\"\n",
        "    返回形状为 (num_users, max_len) 的 LongTensor。\n",
        "    第 i 行是用户 i 的历史序列，左侧 PAD，右对齐。\n",
        "    不存在历史的用户整行都是 pad_idx。\n",
        "    \"\"\"\n",
        "    # 先全部填 PAD\n",
        "    hist = torch.full((num_users, max_len), pad_idx, dtype=torch.long)\n",
        "\n",
        "    # groupby 遍历每个用户已有交互\n",
        "    for uid, items in df.groupby(user_col)[item_col]:\n",
        "        seq = items.to_numpy()[-max_len:]             # 取最近 max_len 条\n",
        "        hist[uid, -len(seq):] = torch.as_tensor(seq, dtype=torch.long)\n",
        "\n",
        "    return hist    # (U, T)\n"
      ],
      "id": "9bc49db2aee62849",
      "outputs": [],
      "execution_count": 166
    },
    {
      "cell_type": "code",
      "id": "cd29a40c68841c9c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-07T13:24:01.057232Z",
          "start_time": "2025-06-07T12:50:36.508711Z"
        },
        "id": "cd29a40c68841c9c",
        "outputId": "5eb2aa30-744e-43c1-8814-b1819a5d4886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "    # ------------------ 训练 ------------------\n",
        "model = GRU4Rec(n_items=N_ITEMS,\n",
        "                 embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE,\n",
        "                 num_layers=NUM_LAYERS, pad_idx=PAD_IDX)\n",
        "model = model.to(device)\n",
        "hist_tensors = build_hist_matrix(train_df, max_len=MAX_SEQ_LEN, pad_idx=PAD_IDX,num_users=num_users).to(device)\n",
        "selected_epoch = train_model(model=model,epochs=EPOCHS, train_df=train_df,batch_size=BATCH_SIZE,lr=LR,val_df=val_df,device=device,patience=PATIENCE,monitor=MONITOR,record_path=record_path,top_k=TOP_K,val_mode=True)\n",
        "    # ------------------ 训练 ------------------\n",
        "model = GRU4Rec(n_items=N_ITEMS,\n",
        "                 embedding_dim=EMBEDDING_DIM, hidden_size=HIDDEN_SIZE,\n",
        "                 num_layers=NUM_LAYERS, pad_idx=PAD_IDX)\n",
        "model = model.to(device)\n",
        "hist_tensors = build_hist_matrix(train_all_df, max_len=MAX_SEQ_LEN, pad_idx=PAD_IDX,num_users=num_users).to(device)\n",
        "train_model(model=model,epochs=selected_epoch, train_df=train_all_df,batch_size=BATCH_SIZE,lr=LR,val_df=test_df,device=device,patience=PATIENCE,monitor=MONITOR,record_path=record_path,top_k=TOP_K,val_mode=False)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EarlyStopping] monitor=hr@10 , patience=5\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 01/60] avg InBatch Softmax Loss = 6.2875, HR@10 = 0.0326, NDCG@10 = 0.0156, alpha=0.4923374056816101, beta=0.4836830496788025, time = 1.99s\n",
            "current best hr@10=0.0326 @ epoch 1.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 02/60] avg InBatch Softmax Loss = 5.7504, HR@10 = 0.0546, NDCG@10 = 0.0259, alpha=0.5016434192657471, beta=0.4771975576877594, time = 1.82s\n",
            "current best hr@10=0.0546 @ epoch 2.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 03/60] avg InBatch Softmax Loss = 5.4258, HR@10 = 0.0647, NDCG@10 = 0.0315, alpha=0.5134395956993103, beta=0.47511619329452515, time = 1.87s\n",
            "current best hr@10=0.0647 @ epoch 3.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 04/60] avg InBatch Softmax Loss = 5.2667, HR@10 = 0.0688, NDCG@10 = 0.0343, alpha=0.5250577926635742, beta=0.47088536620140076, time = 1.92s\n",
            "current best hr@10=0.0688 @ epoch 4.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 05/60] avg InBatch Softmax Loss = 5.1727, HR@10 = 0.0712, NDCG@10 = 0.0356, alpha=0.5395343899726868, beta=0.4682331085205078, time = 1.87s\n",
            "current best hr@10=0.0712 @ epoch 5.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 06/60] avg InBatch Softmax Loss = 5.1012, HR@10 = 0.0739, NDCG@10 = 0.0372, alpha=0.5524740815162659, beta=0.4629802703857422, time = 1.84s\n",
            "current best hr@10=0.0739 @ epoch 6.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 07/60] avg InBatch Softmax Loss = 5.0433, HR@10 = 0.0746, NDCG@10 = 0.0371, alpha=0.5659394264221191, beta=0.45802775025367737, time = 2.19s\n",
            "current best hr@10=0.0746 @ epoch 7.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 08/60] avg InBatch Softmax Loss = 4.9909, HR@10 = 0.0762, NDCG@10 = 0.0378, alpha=0.5783302783966064, beta=0.4544745087623596, time = 2.13s\n",
            "current best hr@10=0.0762 @ epoch 8.\n",
            "Best result info saved to ./records/validation mode/best_result.txt\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 09/60] avg InBatch Softmax Loss = 4.9420, HR@10 = 0.0757, NDCG@10 = 0.0377, alpha=0.5899136662483215, beta=0.4511806070804596, time = 1.87s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 10/60] avg InBatch Softmax Loss = 4.8989, HR@10 = 0.0758, NDCG@10 = 0.0380, alpha=0.6009068489074707, beta=0.44965803623199463, time = 1.88s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 11/60] avg InBatch Softmax Loss = 4.8594, HR@10 = 0.0754, NDCG@10 = 0.0377, alpha=0.6118922233581543, beta=0.44834601879119873, time = 1.86s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 12/60] avg InBatch Softmax Loss = 4.8203, HR@10 = 0.0751, NDCG@10 = 0.0378, alpha=0.6202765107154846, beta=0.44849178194999695, time = 1.92s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 13/60] avg InBatch Softmax Loss = 4.7851, HR@10 = 0.0750, NDCG@10 = 0.0372, alpha=0.6288149356842041, beta=0.4507797360420227, time = 1.85s\n",
            "Early stopping triggered.\n",
            "Saved ./records/validation mode/curve_loss.png\n",
            "Saved ./records/validation mode/curve_metrics.png\n",
            "Saved ./records/validation mode/curve_alpha_beta.png\n",
            "Best hr@10=0.0762 at epoch 8\n",
            "[EarlyStopping] monitor=hr@10 , patience=5\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 01/8] avg InBatch Softmax Loss = 6.2381, HR@10 = 0.0400, NDCG@10 = 0.0188, alpha=0.4970860779285431, beta=0.4808881878852844, time = 2.22s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 02/8] avg InBatch Softmax Loss = 5.6327, HR@10 = 0.0661, NDCG@10 = 0.0317, alpha=0.5084882378578186, beta=0.4739236533641815, time = 2.13s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 03/8] avg InBatch Softmax Loss = 5.3446, HR@10 = 0.0715, NDCG@10 = 0.0352, alpha=0.5255784392356873, beta=0.471285879611969, time = 2.25s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 04/8] avg InBatch Softmax Loss = 5.2178, HR@10 = 0.0752, NDCG@10 = 0.0377, alpha=0.5458599925041199, beta=0.4676661491394043, time = 2.22s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 05/8] avg InBatch Softmax Loss = 5.1346, HR@10 = 0.0780, NDCG@10 = 0.0384, alpha=0.5657311081886292, beta=0.4623049199581146, time = 2.24s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 06/8] avg InBatch Softmax Loss = 5.0732, HR@10 = 0.0795, NDCG@10 = 0.0395, alpha=0.5840374231338501, beta=0.45416027307510376, time = 2.22s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 07/8] avg InBatch Softmax Loss = 5.0221, HR@10 = 0.0800, NDCG@10 = 0.0399, alpha=0.6029244065284729, beta=0.44788244366645813, time = 2.21s\n",
            "Saved item embeddings and FAISS index.\n",
            "[Epoch 08/8] avg InBatch Softmax Loss = 4.9743, HR@10 = 0.0803, NDCG@10 = 0.0399, alpha=0.6205158829689026, beta=0.4416888356208801, time = 2.22s\n",
            "Saved ./records/train mode/curve_loss.png\n",
            "Saved ./records/train mode/curve_metrics.png\n",
            "Saved ./records/train mode/curve_alpha_beta.png\n",
            "Best hr@10=-inf at epoch -1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ],
      "execution_count": 167
    },
    {
      "metadata": {
        "id": "9db4fac4ac9a88f1",
        "outputId": "6964b051-26fd-4246-82df-9b0efbfafbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved item embeddings and FAISS index.\n"
          ]
        }
      ],
      "execution_count": 168,
      "source": [
        "model.save_embeddings(num_users=num_users,num_items=num_items,device=device,save_dir=save_dir)"
      ],
      "id": "9db4fac4ac9a88f1"
    },
    {
      "metadata": {
        "id": "236d0215db2d03ac"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 169,
      "source": [
        "test_loader = customdataset.build_test_loader(test_df, num_items ,user_col = user_id, item_col = item_id, batch_size=1024, num_workers=NUM_WORKERS)\n",
        "item_pool = list(range(num_items))\n",
        "faiss_index = faiss.read_index(f\"{save_dir}/item_index.faiss\")"
      ],
      "id": "236d0215db2d03ac"
    },
    {
      "metadata": {
        "id": "abe3041361cf8ecd",
        "outputId": "0f1ffd09-e610-4c22-f766-f9c2bf4cdce9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random HR@10 = 0.0005, NDCG@10 = 0.0002\n",
            "Popular HR@10 = 0.0030, NDCG@10 = 0.0014\n",
            "Model   HR@10 = 0.0803, NDCG@10 = 0.0399\n"
          ]
        }
      ],
      "execution_count": 170,
      "source": [
        "hr_r, ndcg_r = evaluate.evaluate_random(test_loader, item_pool ,top_k=TOP_K)\n",
        "print(f\"Random HR@{TOP_K} = {hr_r:.4f}, NDCG@{TOP_K} = {ndcg_r:.4f}\")\n",
        "hr_p, ndcg_p = evaluate.evaluate_popular(test_loader, train_all_df,top_k=TOP_K)\n",
        "print(f\"Popular HR@{TOP_K} = {hr_p:.4f}, NDCG@{TOP_K} = {ndcg_p:.4f}\")\n",
        "hr_m, ndcg_m = evaluate.evaluate_seq_model(test_loader, model, faiss_index, device,top_k=TOP_K,hist_tensors=hist_tensors)\n",
        "print(f\"Model   HR@{TOP_K} = {hr_m:.4f}, NDCG@{TOP_K} = {ndcg_m:.4f}\")"
      ],
      "id": "abe3041361cf8ecd"
    },
    {
      "metadata": {
        "id": "9cb8be5f55ace237",
        "outputId": "2448fc82-f4f8-40de-d217-debb46ac1be6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "execution_count": 171,
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 挂载 Google Drive\n",
        "drive.mount('/content/drive')\n",
        "# 目标路径\n",
        "target_dir = None\n",
        "if(FUSION_MODE==\"base\"):\n",
        "    target_dir = f\"/content/drive/MyDrive/REC/{PROJECT_NAME}/{FUSION_MODE}/\"\n",
        "else:\n",
        "    target_dir = f\"/content/drive/MyDrive/REC/{PROJECT_NAME}/{FUSION_MODE}/{CURRENT_MODAL}\"\n",
        "# 创建目标路径（包含上层目录）\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "# 复制 records 到目标路径\n",
        "!cp -r /content/records \"{target_dir}\"\n",
        "!rm -rf /content/records"
      ],
      "id": "9cb8be5f55ace237"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}