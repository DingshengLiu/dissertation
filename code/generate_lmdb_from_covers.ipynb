{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-29T21:35:59.618971Z",
     "start_time": "2025-06-29T21:35:26.414172Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "一次性生成 128 维图片 embedding 并写入 LMDB。\n",
    "作者：ChatGPT 2025-06-29\n",
    "\"\"\"\n",
    "\n",
    "import os, glob, lmdb, numpy as np, torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import clip\n",
    "from torchvision import transforms\n",
    "\n",
    "# --------------- 配置 ---------------\n",
    "ROOT_DIR   = r\"D:\\VideoRecSystem\\MicroLens\\DataSet\"\n",
    "LMDB_PATH  = r\"D:\\VideoRecSystem\\MicroLens\\cover_emb128.lmdb\"\n",
    "MAP_SIZE   = 256 << 20          # 256 MB upper-bound\n",
    "BATCH_SIZE = 64               # 调大/调小按显存来\n",
    "OUT_DIM    = 128              # 目标维度\n",
    "PCA_BATCH  = 2048             # IncrementalPCA 每批样本数\n",
    "\n",
    "# --------------- 预处理 & 模型 ---------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)   # 输出 512 维\n",
    "\n",
    "model = model.to(device).eval()       # 输出 512 维\n",
    "\n",
    "\n",
    "# ------- 收集并排序 jpg（保持不变） -------\n",
    "def collect_images(root):\n",
    "    paths = glob.glob(os.path.join(root, \"*.jpg\"))\n",
    "    paths = [p for p in paths if \"-\" not in os.path.basename(p)]\n",
    "    # 按文件名里的数字顺序排：1.jpg -> 2.jpg -> ...\n",
    "    paths.sort(key=lambda x: int(os.path.splitext(os.path.basename(x))[0]))\n",
    "    return paths\n",
    "\n",
    "img_paths = collect_images(ROOT_DIR)\n",
    "print(f\"Found {len(img_paths)} valid jpg files.\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19220 valid jpg files.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:49:01.179491Z",
     "start_time": "2025-06-29T21:35:59.663032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------- 第 1 步：增量 PCA 拟合 ---------------\n",
    "pca = IncrementalPCA(n_components=OUT_DIM)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for s in tqdm(range(0, len(img_paths), PCA_BATCH), desc=\"Fit PCA\"):\n",
    "        batch = img_paths[s:s + PCA_BATCH]\n",
    "        imgs  = [preprocess(Image.open(p).convert(\"RGB\")) for p in batch]\n",
    "        feats = torch.stack(imgs).to(device)\n",
    "\n",
    "        feats = model.encode_image(feats).cpu().numpy().astype(np.float32)  # (B,512)\n",
    "        pca.partial_fit(feats)\n",
    "\n",
    "print(\"PCA fitting done.\")\n"
   ],
   "id": "52cfbf614efdc53d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fit PCA: 100%|██████████| 10/10 [13:01<00:00, 78.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA fitting done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:58:57.546745Z",
     "start_time": "2025-06-29T21:49:02.740740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------- 第 2 步：提特征 → 降维 → 写 LMDB ---------------\n",
    "env = lmdb.open(LMDB_PATH, map_size=MAP_SIZE, subdir=False)\n",
    "\n",
    "with env.begin(write=True) as txn, torch.no_grad():\n",
    "    # 把 PCA 参数也存进去，后续可复用\n",
    "    txn.put(b\"__pca_mean__\", pca.mean_.astype(np.float32).tobytes())\n",
    "    txn.put(b\"__pca_components__\", pca.components_.astype(np.float32).tobytes())\n",
    "    txn.put(b\"__dim__\", np.array([OUT_DIM], dtype=np.int32).tobytes())\n",
    "\n",
    "    for s in tqdm(range(0, len(img_paths), BATCH_SIZE), desc=\"Embed & Store\"):\n",
    "        batch = img_paths[s:s + BATCH_SIZE]\n",
    "        imgs  = [preprocess(Image.open(p).convert(\"RGB\")) for p in batch]\n",
    "        feats128 = pca.transform(model.encode_image(torch.stack(imgs).to(device))\n",
    "                                 .cpu().numpy().astype(np.float32))\n",
    "\n",
    "        for path, vec in zip(batch, feats128):\n",
    "            item_id = int(os.path.splitext(os.path.basename(path))[0])   # 1, 2, ...\n",
    "            key = f\"{item_id:08d}\".encode()   # 00000001, 00000002 …\n",
    "            txn.put(key, vec.tobytes())\n",
    "\n",
    "print(\"✅ 128-dim embeddings saved to\", LMDB_PATH)"
   ],
   "id": "ff0f14219770798",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embed & Store: 100%|██████████| 301/301 [09:54<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 128-dim embeddings saved to D:\\VideoRecSystem\\MicroLens\\cover_emb128.lmdb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
