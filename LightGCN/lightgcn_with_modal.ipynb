{
 "cells": [
  {
   "metadata": {
    "id": "a8786635ccc5e581",
    "outputId": "25bba827-18cb-4bec-ccdc-850188c0c965",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "skip:/content/tool exists\n",
      "skip:/content/MicroLens-50k_pairs.csv exists\n",
      "skip:/content/cover_emb128.lmdb exists\n"
     ]
    }
   ],
   "execution_count": 33,
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "def copy_from_drive(src_path, dst_path):\n",
    "\n",
    "    if os.path.exists(dst_path):\n",
    "        print(f\"skip:{dst_path} exists\")\n",
    "        return\n",
    "\n",
    "    if os.path.isdir(src_path):\n",
    "        shutil.copytree(src_path, dst_path)\n",
    "    elif os.path.isfile(src_path):\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "copy_from_drive('/content/drive/MyDrive/tool', '/content/tool')\n",
    "copy_from_drive('/content/drive/MyDrive/MicroLens-50k_pairs.csv','/content/MicroLens-50k_pairs.csv')\n",
    "copy_from_drive('/content/drive/MyDrive/cover_emb128.lmdb','/content/cover_emb128.lmdb')\n",
    "copy_from_drive('/content/drive/MyDrive/title_emb1024.lmdb','/content/title_emb1024.lmdb')"
   ],
   "id": "a8786635ccc5e581"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b828e981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:13.343878Z",
     "start_time": "2025-04-30T20:26:13.338767Z"
    },
    "id": "b828e981",
    "outputId": "86a95f64-c6e8-4161-f4c0-3c068bf56f48",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
      "Requirement already satisfied: lmdb in /usr/local/lib/python3.11/dist-packages (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "!pip install lmdb\n",
    "from tool import preprocess\n",
    "from tool import customdataset\n",
    "from tool import evaluate\n",
    "import faiss\n",
    "from datetime import datetime\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "id": "bad1b340170c222f",
    "outputId": "1c09b786-0952-4d40-d41e-bd0696f3803f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function tool.preprocess.set_seed.<locals>.seed_worker(worker_id)>"
      ],
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>tool.preprocess.set_seed.&lt;locals&gt;.seed_worker</b><br/>def seed_worker(worker_id)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/tool/preprocess.py</a>&lt;no docstring&gt;</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 18);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "execution_count": 35,
   "source": [
    "preprocess.set_seed(42)"
   ],
   "id": "bad1b340170c222f"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e99a31348e0a553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:13.391974Z",
     "start_time": "2025-04-30T20:26:13.387554Z"
    },
    "id": "e99a31348e0a553"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76a2087d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:13.572661Z",
     "start_time": "2025-04-30T20:26:13.416069Z"
    },
    "id": "76a2087d"
   },
   "outputs": [],
   "source": [
    "# dataset_pd = pd.read_csv('D:\\\\VideoRecSystem\\\\MicroLens\\\\DataSet\\\\MicroLens-50k_pairs.csv')\n",
    "path = 'MicroLens-50k_pairs.csv'\n",
    "cover_lmdb_path = 'cover_emb128.lmdb'\n",
    "title_lmdb_path = 'title_emb1024.lmdb'\n",
    "user = 'user'\n",
    "item = 'item'\n",
    "user_id = 'user_id'\n",
    "item_id = 'item_id'\n",
    "timestamp = 'timestamp'\n",
    "save_dir = './embeddings'\n",
    "N_LAYERS = 2\n",
    "EMBEDDING_DIM = 64\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1E-3\n",
    "MODAL = {'COVER':{\"LMDB_DIM\":128, \"HIDDEN_SIZE\":[EMBEDDING_DIM],\"DROPOUT\":0.2} , 'TITLE':{\"LMDB_DIM\":1024,\"HIDDEN_SIZE\":[EMBEDDING_DIM],\"DROPOUT\":0.2}\n",
    "         ,'COVER-TITLE': {\"LMDB_DIM\":128+1024, \"HIDDEN_SIZE\":[EMBEDDING_DIM],\"DROPOUT\":0.2}}\n",
    "CURRENT_MODAL = \"COVER\"\n",
    "MODAL_CONFIG = MODAL[CURRENT_MODAL]\n",
    "MODAL_HIDDEN_SIZE = MODAL_CONFIG.get('HIDDEN_SIZE')\n",
    "LMDB_DIM = MODAL_CONFIG.get('LMDB_DIM')\n",
    "MODAL_DROPOUT = MODAL_CONFIG.get('DROPOUT')\n",
    "FUSION_MODE = \"late\"\n",
    "DROPOUT = 0.2\n",
    "L2_NORM = False\n",
    "top_k = 10\n",
    "num_workers = 10\n",
    "k_neg = 10\n",
    "# path = pd.read_csv('MicroLens-50k_pairs.csv')\n",
    "# dataset_pd = pd.read_csv('MicroLens-50k_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "943fc6c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:13.615265Z",
     "start_time": "2025-04-30T20:26:13.605752Z"
    },
    "id": "943fc6c5",
    "outputId": "4309fbfc-e4a2-41fe-e823-440e42d2c254",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset base information：\n",
      "- number of users：50000\n",
      "- number of items：19220\n",
      "- number of rows：359708\n"
     ]
    }
   ],
   "source": [
    "dataset_pd,num_users,num_items = preprocess.openAndSort(path,user_id=user,item_id=item,timestamp='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69160caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:13.713174Z",
     "start_time": "2025-04-30T20:26:13.702986Z"
    },
    "id": "69160caa",
    "outputId": "e04a61e3-7f88-4d3e-b776-50292aba54b6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train size: 309708\n",
      "Test size: 49424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df, test_df = preprocess.split(dataset_pd,user, item, timestamp)\n",
    "print(f\"Train size: {len(train_df)}\")\n",
    "print(f\"Test size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d42c375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:13.848465Z",
     "start_time": "2025-04-30T20:26:13.789646Z"
    },
    "id": "6d42c375"
   },
   "outputs": [],
   "source": [
    "# maintain a map from new id to old id, new id for constructing matrix\n",
    "user2id = {u: i for i, u in enumerate(dataset_pd[user].unique())}\n",
    "item2id = {i: j for j, i in enumerate(dataset_pd[item].unique())}\n",
    "\n",
    "# apply to train_df and test_df\n",
    "train_df[user_id] = train_df[user].map(user2id)\n",
    "train_df[item_id] = train_df[item].map(item2id)\n",
    "test_df[user_id] = test_df[user].map(user2id)\n",
    "test_df[item_id] = test_df[item].map(item2id)\n",
    "\n",
    "# 1. 构建 item_id 到 item 的映射（来自 train_df）\n",
    "item_id_to_item = {v: k for k, v in item2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a28cf3d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:15.725506Z",
     "start_time": "2025-04-30T20:26:15.717Z"
    },
    "id": "a28cf3d3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_adj_matrix(df, num_users, num_items ,user_id, item_id):\n",
    "    rows = df[user_id].values\n",
    "    cols = df[item_id].values\n",
    "    data = np.ones(len(df))\n",
    "    # set interaction of user-item as 1, other as 0\n",
    "    R = sp.coo_matrix((data, (rows, cols)), shape=(num_users, num_items))\n",
    "\n",
    "    # construct symetric matrix A\n",
    "    upper = sp.hstack([sp.csr_matrix((num_users, num_users)), R])\n",
    "    lower = sp.hstack([R.T, sp.csr_matrix((num_items, num_items))])\n",
    "    A = sp.vstack([upper, lower])\n",
    "\n",
    "    # normalization A → Ĥ = D^{-1/2} A D^{-1/2}\n",
    "    rowsum = np.array(A.sum(1)).flatten()\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5)\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    D_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    A_norm = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "    # transform to torch.sparse\n",
    "    A_norm = A_norm.tocoo()\n",
    "    indices = torch.LongTensor([A_norm.row, A_norm.col])\n",
    "    values = torch.FloatTensor(A_norm.data)\n",
    "    return torch.sparse_coo_tensor(indices, values, A_norm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d9cee55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:16.173195Z",
     "start_time": "2025-04-30T20:26:15.789923Z"
    },
    "id": "3d9cee55",
    "outputId": "9166dfca-cf52-486d-a429-c18ddc03f4fc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipython-input-2216191345.py:15: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv_sqrt = np.power(rowsum, -0.5)\n"
     ]
    }
   ],
   "source": [
    "adj_torch = build_adj_matrix(train_df, num_users, num_items ,user_id, item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7aba75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:26:16.197535Z",
     "start_time": "2025-04-30T20:26:16.187729Z"
    },
    "id": "a7aba75c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, n_layers, adjacency,\n",
    "                 lmdb_dim=LMDB_DIM, modal_hidden_size=MODAL_HIDDEN_SIZE, modal_dropout=MODAL_DROPOUT,\n",
    "                 fusion_mode=FUSION_MODE):  # 'none' | 'early' | 'late'\n",
    "        super(LightGCN, self).__init__()\n",
    "        assert fusion_mode in {'none', 'early', 'late'}\n",
    "        self.fusion_mode   = fusion_mode\n",
    "        self.user_emb      = None\n",
    "        self.item_emb      = None\n",
    "        self.num_users     = num_users\n",
    "        self.num_items     = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers      = n_layers\n",
    "        self.adjacency     = adjacency  # torch.sparse_coo_tensor\n",
    "\n",
    "        # ----- ID embeddings -----\n",
    "        self.embedding_user = nn.Embedding(num_users, embedding_dim)\n",
    "        self.embedding_item = nn.Embedding(num_items, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding_user.weight)\n",
    "        nn.init.xavier_uniform_(self.embedding_item.weight)\n",
    "\n",
    "        # modal 向量（冻结）\n",
    "        modal_emb_tensor = None\n",
    "        if CURRENT_MODAL=='COVER':\n",
    "            modal_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
    "                cover_lmdb_path, num_items, item_id_to_item, lmdb_dim\n",
    "            )\n",
    "        if CURRENT_MODAL=='TITLE':\n",
    "            modal_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
    "                title_lmdb_path, num_items, item_id_to_item, lmdb_dim\n",
    "            )\n",
    "        if CURRENT_MODAL=='COVER-TITLE':\n",
    "            cover_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
    "                cover_lmdb_path, num_items, item_id_to_item, 128\n",
    "            )\n",
    "            title_emb_tensor = preprocess.load_tensor_from_lmdb(\n",
    "                title_lmdb_path, num_items, item_id_to_item, 1024\n",
    "            )\n",
    "            modal_emb_tensor = torch.cat([cover_emb_tensor, title_emb_tensor], dim=-1)\n",
    "\n",
    "        self.register_buffer('frozen_extra_emb', modal_emb_tensor)\n",
    "\n",
    "\n",
    "        # ----- 前融合投影：[item_id_emb; modal] -> emb_dim -----\n",
    "        self.mlp_item_modal = self.build_mlp(embedding_dim + lmdb_dim, modal_hidden_size, modal_dropout)\n",
    "\n",
    "        # ----- 后融合用 α（全局标量）-----\n",
    "        # sigmoid(0)=0.5；如需更稳可改为 1.0 使初期更偏向 ID\n",
    "        self.alpha_param = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def build_mlp(self, input_dim, hidden_sizes, dropout):\n",
    "        layers = []\n",
    "        for h in hidden_sizes:\n",
    "            layers += [nn.Linear(input_dim, h), nn.BatchNorm1d(h), nn.Tanh(), nn.Dropout(dropout)]\n",
    "            input_dim = h\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    # ============ LightGCN 传播（给定初始 user/item 表示） ============\n",
    "    @torch.no_grad()\n",
    "    def _propagate(self, user_init, item_init):\n",
    "        \"\"\"\n",
    "        user_init: (U, D), item_init: (I, D)\n",
    "        返回经 n_layers LightGCN 平均聚合后的 (user_emb, item_emb)\n",
    "        \"\"\"\n",
    "        all_embeddings = torch.cat([user_init, item_init], dim=0)   # (U+I, D)\n",
    "        embs = [all_embeddings]\n",
    "        for _ in range(self.n_layers):\n",
    "            all_embeddings = torch.sparse.mm(self.adjacency, all_embeddings)\n",
    "            embs.append(all_embeddings)\n",
    "        final = torch.stack(embs, dim=1).mean(dim=1)                # (U+I, D)\n",
    "        user_embedding, item_embedding = torch.split(final, [self.num_users, self.num_items])\n",
    "        return user_embedding, item_embedding\n",
    "\n",
    "    def _item_init_id_only(self):\n",
    "        return self.embedding_item.weight                             # (I, D)\n",
    "\n",
    "    def _item_init_early(self):\n",
    "        # [id_emb; modal] -> emb_dim\n",
    "        modal = self.frozen_extra_emb.to(self.embedding_item.weight.device)  # (I, C)\n",
    "        i_cat = torch.cat([self.embedding_item.weight, modal], dim=-1)       # (I, D+C)\n",
    "        i_emb = self.mlp_item_modal(i_cat)                                   # (I, D)\n",
    "        return i_emb\n",
    "\n",
    "    # ============ 前向：生成/缓存用户与物品图表示 ============\n",
    "    def forward(self):\n",
    "        device = self.embedding_item.weight.device\n",
    "        user_init = self.embedding_user.weight                              # (U, D)\n",
    "\n",
    "        if self.fusion_mode == 'none':\n",
    "            # 纯 ID：一次传播\n",
    "            item_init = self._item_init_id_only()\n",
    "            user_embedding, item_embedding = self._propagate(user_init, item_init)\n",
    "\n",
    "        elif self.fusion_mode == 'early':\n",
    "            # 前融合：先做模态映射，再作为图的初始 item 表示\n",
    "            item_init = self._item_init_early()\n",
    "            user_embedding, item_embedding = self._propagate(user_init, item_init)\n",
    "\n",
    "        else:  # 'late'\n",
    "            # 后融合：两条路径分别图传播，最后在图传播结果处做 α 加权（仅对 item）\n",
    "            item_init_id = self._item_init_id_only()\n",
    "            item_init_mm = self._item_init_early()\n",
    "\n",
    "            # 两次传播（共享同一 user_init）\n",
    "            user_id_emb,  item_id_emb  = self._propagate(user_init, item_init_id)\n",
    "            user_mm_emb,  item_mm_emb  = self._propagate(user_init, item_init_mm)\n",
    "\n",
    "            alpha = torch.sigmoid(self.alpha_param).to(device)  # 标量\n",
    "            item_embedding = alpha * item_id_emb + (1.0 - alpha) * item_mm_emb\n",
    "            # 用户侧：为最小改动与稳定性，采用 ID 路径的 user 表示（也可两路再平均/融合）\n",
    "            user_embedding = user_id_emb\n",
    "\n",
    "        # 缓存（评测/导出用）\n",
    "        self.user_emb = user_embedding.detach()\n",
    "        self.item_emb = item_embedding.detach()\n",
    "        return user_embedding, item_embedding\n",
    "\n",
    "    # ============ Getter（评测/召回） ============\n",
    "    def get_users_embedding(self, user_ids, l2_norm=False):\n",
    "        u_vec = self.user_emb[user_ids]\n",
    "        if l2_norm:\n",
    "            u_vec = F.normalize(u_vec, p=2, dim=1)\n",
    "        return u_vec\n",
    "\n",
    "    def get_items_embedding(self, item_ids, l2_norm=False):\n",
    "        i_vec = self.item_emb[item_ids]\n",
    "        if l2_norm:\n",
    "            i_vec = F.normalize(i_vec, p=2, dim=1)\n",
    "        return i_vec\n",
    "\n",
    "    # ============ 导出 ============\n",
    "    def save_embeddings(self, num_users, num_items, device, save_dir='./embeddings', l2_norm=L2_NORM):\n",
    "        import os, faiss\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        self.eval().to(device)\n",
    "\n",
    "        user_ids = torch.arange(num_users, dtype=torch.long, device=device)\n",
    "        item_ids = torch.arange(num_items, dtype=torch.long, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            user_embeds = self.get_users_embedding(user_ids, l2_norm=l2_norm)\n",
    "            item_embeds = self.get_items_embedding(item_ids, l2_norm=l2_norm)\n",
    "\n",
    "        user_embeds = user_embeds.cpu().numpy().astype(np.float32)\n",
    "        item_embeds = item_embeds.cpu().numpy().astype(np.float32)\n",
    "\n",
    "        np.save(f\"{save_dir}/user_embeddings.npy\", user_embeds)\n",
    "        np.save(f\"{save_dir}/item_embeddings.npy\", item_embeds)\n",
    "\n",
    "        dim = item_embeds.shape[1]\n",
    "        index = faiss.IndexFlatIP(dim)\n",
    "        index.add(item_embeds)\n",
    "        faiss.write_index(index, f\"{save_dir}/item_index.faiss\")\n",
    "        print(\"Saved user/item embeddings and FAISS index.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "07e268c2",
   "metadata": {
    "id": "07e268c2",
    "ExecuteTime": {
     "end_time": "2025-08-06T15:52:33.410720Z",
     "start_time": "2025-08-06T15:52:01.496763Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model,\n",
    "                train_df,\n",
    "                num_items,\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                lr=LR,\n",
    "                device=None):\n",
    "    \"\"\"\n",
    "    训练 LightGCN (或其它 BPR 模型) 的通用函数\n",
    "    ------------------------------------------------\n",
    "    • train_df      : pandas DataFrame，含 user_id / item_id\n",
    "    • num_items     : 物品总数\n",
    "    • device        : torch.device；默认为 'cuda' (若可用) 否则 'cpu'\n",
    "    • max_grad_norm : 梯度裁剪阈值；避免梯度爆炸，可选\n",
    "    \"\"\"\n",
    "    # -------- 设备 ----------\n",
    "    if device is None:\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = model.to(device)\n",
    "    if hasattr(model, \"adjacency\"):               # adjacency 可能是稀疏张量\n",
    "        model.adjacency = model.adjacency.to(device)\n",
    "\n",
    "    # -------- 优化器 ----------\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_loader = customdataset.build_train_loader_inbatch(train_df, batch_size=batch_size,user_col=user_id, item_col=item_id)\n",
    "\n",
    "    # -------- 训练循环 ----------\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        dt_start = datetime.now()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            user_ids, pos_item_ids = batch\n",
    "            user_ids = user_ids.to(device).long()\n",
    "            pos_item_ids = pos_item_ids.to(device).long()\n",
    "\n",
    "\n",
    "            # 1. 前向传播（返回 user / item 向量）\n",
    "            user_emb, item_emb = model()\n",
    "            u_vec = user_emb[user_ids]\n",
    "            i_vec = item_emb[pos_item_ids]\n",
    "\n",
    "            # 2. 得分矩阵：每个 user 对所有正 item 的打分\n",
    "            logits = torch.matmul(u_vec, i_vec.T)  # shape: (B, B)\n",
    "\n",
    "            # 3. 构造标签：每个 user 的正确 item 在对角线（即位置 i）\n",
    "            labels = torch.arange(logits.size(0), device=device)  # [0, 1, ..., B-1]\n",
    "\n",
    "            # 4. Cross Entropy Loss\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "            # 5. 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # 日志\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        dt_end = datetime.now()\n",
    "        dt = dt_end - dt_start\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}/{epochs}] avg InBatch Softmax Loss = {avg_loss:.4f}, time = {dt.total_seconds():.2f}s\")\n",
    "        if(model.fusion_mode=='late'):\n",
    "            print('alpha:', torch.sigmoid(model.alpha_param).item())\n",
    "    return\n"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd29a40c68841c9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T20:34:51.542117Z",
     "start_time": "2025-04-30T20:26:16.696795Z"
    },
    "id": "cd29a40c68841c9c",
    "outputId": "a248fe60-01f2-4d65-c5ba-ba08ad6e0472",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Epoch 01/8] avg InBatch Softmax Loss = 5.5854, time = 3.65s\n",
      "[Epoch 02/8] avg InBatch Softmax Loss = 4.9674, time = 3.65s\n",
      "[Epoch 03/8] avg InBatch Softmax Loss = 4.6006, time = 3.65s\n",
      "[Epoch 04/8] avg InBatch Softmax Loss = 4.3015, time = 3.62s\n",
      "[Epoch 05/8] avg InBatch Softmax Loss = 4.0619, time = 3.66s\n",
      "[Epoch 06/8] avg InBatch Softmax Loss = 3.8671, time = 3.62s\n",
      "[Epoch 07/8] avg InBatch Softmax Loss = 3.6975, time = 3.65s\n",
      "[Epoch 08/8] avg InBatch Softmax Loss = 3.5447, time = 3.63s\n"
     ]
    }
   ],
   "source": [
    "model = LightGCN(num_users,num_items,embedding_dim=EMBEDDING_DIM,n_layers=N_LAYERS,adjacency=adj_torch)\n",
    "model.to(device)\n",
    "train_model(model=model,epochs=EPOCHS, train_df=train_df,num_items=num_items,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "metadata": {
    "id": "cc858c515448b5b8",
    "outputId": "effe344e-c633-429f-fe25-a57d14284b47",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved user/item embeddings and FAISS index.\n"
     ]
    }
   ],
   "execution_count": 46,
   "source": [
    "model.save_embeddings(num_users=num_users,num_items=num_items,device=device,save_dir=save_dir)"
   ],
   "id": "cc858c515448b5b8"
  },
  {
   "metadata": {
    "id": "2c5b952e28007084"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 47,
   "source": [
    "test_loader = customdataset.build_test_loader(test_df, num_items ,user_col = user_id, item_col = item_id, batch_size=1024, num_workers=num_workers)\n",
    "item_pool = list(range(num_items))\n",
    "faiss_index = faiss.read_index(f\"{save_dir}/item_index.faiss\")"
   ],
   "id": "2c5b952e28007084"
  },
  {
   "metadata": {
    "id": "ae68d6ba3c864c65",
    "outputId": "89f149e7-392c-4a24-aa50-4446ea928a5e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random HR@10 = 0.0005, nDCG@10 = 0.0002\n",
      "Popular HR@10 = 0.0029, nDCG@10 = 0.0014\n",
      "Model   HR@10 = 0.0294, nDCG@10 = 0.0115\n"
     ]
    }
   ],
   "execution_count": 48,
   "source": [
    "hr_r, ndcg_r = evaluate.evaluate_random(test_loader, item_pool ,top_k=top_k)\n",
    "print(f\"Random HR@{top_k} = {hr_r:.4f}, NDCG@{top_k} = {ndcg_r:.4f}\")\n",
    "hr_p, ndcg_p = evaluate.evaluate_popular(test_loader, train_df,top_k=top_k)\n",
    "print(f\"Popular HR@{top_k} = {hr_p:.4f}, NDCG@{top_k} = {ndcg_p:.4f}\")\n",
    "hr_m, ndcg_m = evaluate.evaluate_model(test_loader, model, faiss_index, device,top_k=top_k)\n",
    "print(f\"Model   HR@{top_k} = {hr_m:.4f}, NDCG@{top_k} = {ndcg_m:.4f}\")\n"
   ],
   "id": "ae68d6ba3c864c65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "colab": {
   "provenance": [],
   "gpuType": "L4",
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
